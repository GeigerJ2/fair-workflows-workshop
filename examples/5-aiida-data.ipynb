{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running our own simulations and workflows, we have now created a bunch of data along the way. So let's see how we can\n",
    "explore it, shall we?\n",
    "\n",
    "As mentioned earlier, AiiDA stores it's data in an internal file repository, as well as an SQL database. The former\n",
    "contains the main input and output files of the calculations, while the latter contains the provenance data, as well as\n",
    "parsed results (only pointers to files are stored in the SQL database). To achieve high performance, these storage\n",
    "solutions are machine-readable, rather than human-readable, so we will require the AiiDA CLI and API to efficiently\n",
    "explore our data. Let's first load our AiiDA profile again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping of process data to disk\n",
    "\n",
    "As of AiiDA v2.6.1, released on 2024-07-01, it is now possible to dump all data involved in the execution of a\n",
    "calculation or workflow to disk in a human-readable, logical directory structure. To achieve this, simply run the\n",
    "following command, e.g. using the PK of your finished `EquationOfStateWorkChain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi process dump <PK>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the command ran successfully, you will now be able to see a directory with the name\n",
    "`dump-EquationOfStateWorkChain-<PK>` in the file explorer of your jupyter instance. The contained files can now be\n",
    "explored using the common Linux command-line tools we all know and love, such as `grep`.\n",
    "\n",
    "More information on the dumping can be found in the [relevant documentation section](https://aiida.readthedocs.io/projects/aiida-core/en/stable/howto/data.html#dumping-data-to-disk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data\n",
    "\n",
    "Talking of directories, it is possible (and recommended for larger studies) to organize your `Node` entities in a\n",
    "logical structure, reminiscent of how one would organize their files and folders in a typical computational research\n",
    "project.\n",
    "\n",
    "For this, AiiDA provides the concept of `Group`s. Let's have a look at our current database using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi group list -aA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pseudopotentials we downloadad previously are actually saved as `Group`s in our database. If we want to\n",
    "create our own groups and add nodes to it, we can do so using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi group create <our-group>\n",
    "%verdi group add-nodes -G <our-group> <PK> <PK>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we can supply a list of PKs or UUIDs to be added to `<our-group>`. To create the previously mentioned\n",
    "directory-like organization, we can use slashes in the group names to create sub-groups that behave like sub-folders\n",
    "would on your file system.\n",
    "\n",
    "This concludes our short introduction to `Group`s, and we point you to the [relevant documentation section for further\n",
    "reading]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The QueryBuilder\n",
    "\n",
    "The main class that can be used for querying data stored in the AiiDA database is the `QueryBuilder`. In this section we\n",
    "will learn how you can use it to explore your previously created data. It transforms your queries written in Python to\n",
    "SQL. \n",
    "So let's get started by importing and instantiating it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'fair-workflows-workshop (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/geiger_j/.aiida_venvs/fair-workflows-workshop/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from aiida import orm\n",
    "\n",
    "qb = orm.QueryBuilder()\n",
    "qb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now `append` entities and relations we want to be querying for. Let's first count how many nodes we actually have\n",
    "in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb.append(orm.Node)\n",
    "qb.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to our simulation results, as we installed the pseudopotentials for the whole periodic table, we already have quite\n",
    "a few nodes contained in our database. Let's now see the`PwCalculation`s we have executed.\n",
    "Note: As this will be an independent query, we will have to create another instance of the `QueryBuilder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(PwCalculation)\n",
    "qb.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, all of our calculations are there. As you could see, the query returned the full node of each `PwCalculation`. If\n",
    "we would only like to obtain individual properties, e.g. the PK, we can `project` those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "qb.append(PwCalculation, project='pk')\n",
    "qb.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can also filter our results. Say, we would only like to obtain calculations that we ran today. We can do so with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    PwCalculation,\n",
    "    filters={'ctime': {'>': datetime.now() - timedelta(days=1)}}\n",
    ")\n",
    "qb.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, it's also possible to chain querying expressions together. This allows you to construct (almost)\n",
    "arbitrarily complex queries. For example, let's obtain the output `StructureData` nodes that were created by our\n",
    "`PwCalculation`s of today. These could be of interest, for instance, if we relaxed the crystal structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    PwCalculation,\n",
    "    filters={'ctime': {'>': datetime.now() - timedelta(days=1)}},\n",
    "    tag=\"calculation\"\n",
    ")\n",
    "qb.append(orm.StructureData, with_incoming=\"calculation\")\n",
    "qb.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, we first `tag` our query for the `PwCalculation`s, so that we can link it to the second query we append to the `QueryBuilder`. We use the `with_incoming` argument, as the `StructureData` is an outgoing link of the `PwCalculation`.\n",
    "\n",
    "This concludes our short introduction to the `QueryBuilder`. Of course, it provides many more capabilities so we refer\n",
    "you to the [relevant documentation on querying for data]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now reached the end of our tutorial notebooks. We hope we could give you an overview of how you can get\n",
    "started with AiiDA and what it can do for you.\n",
    "\n",
    "If you want to continue your journey, good next steps are the [extensive AiiDA documentation on `readthedocs`](https://aiida.readthedocs.io/projects/aiida-core/en/stable/)\n",
    "where you can find `How-To` guides on\n",
    "common tasks, as well as in-depth information about the cogs and wheels that power AiiDA.\n",
    "\n",
    "We are also holding **regular week-long (virtual) tutorials**. The content of the last one can be found [here](https://aiida-tutorials.readthedocs.io/en/latest/), and goes\n",
    "much more in-depth than we could do so in the limited time today. We are also planning another virtual tutorial in early 2025,\n",
    "which will also highlight recent new features of AiiDA and improvements on usability, so keep your eyes\n",
    "open.\n",
    "\n",
    "If you have any issues, don't hesitate to reach out for help on our [Discourse support platform](https://aiida.discourse.group). Lastly, if you\n",
    "want to use and further explore AiiDA, but are not very keen on coding, [AiiDAlab](https://aiidalab.readthedocs.io/en/latest/) provides you with a jupyter-based\n",
    "graphical user interface that you can use to run the turn-key workflows provided by AiiDA with just a few clicks.\n",
    "\n",
    "Happy computing!\n",
    "\n",
    "The AiiDA team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair-workflows-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
