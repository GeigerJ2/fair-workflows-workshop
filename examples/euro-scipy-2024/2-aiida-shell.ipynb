{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to quickly create a workflow from a set of executables\n",
    "\n",
    "**Please note, this notebook depends on successful execution of the first notebook `1-aiida-intro.ipynb`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Concatenating several scripts to one workflow\n",
    "\n",
    "### The workflow setup\n",
    "\n",
    "Now that we have a working profile set up, assume we would like to execute a workflow that is composed of the following\n",
    "steps:\n",
    "\n",
    "- 1. Create a database that contains some matrices \n",
    "- 2. Run a code that achieves matrix diagonalizations and writes the eigenvalues and eigenvectors to files on disk\n",
    "- 3. Plot the results from the previous steps\n",
    "\n",
    "For this tutorial, the chosen example serves mainly demonstration purposes. However, to motivate our choices of\n",
    "tasks, one could imagine the following concrete use cases:\n",
    "\n",
    "- 1. Query and download atomic structures from a materials database via their API\n",
    "- 2. Run structure optimizations using Quantum Mechanical codes like QE (these, like many other numerical codes, run\n",
    "     many matrix diagonalizations)\n",
    "- 3. Visualize our results for a scientific publication\n",
    "\n",
    "Note that AiiDA was originally created for materials science applications, so we are aware that the examples reflect\n",
    "that. If you think of other use cases, feel free to implement them after this tutorial and let us know about them :star: \n",
    "\n",
    "Each of the steps of our workflow can be of arbitrary nature, e.g. an executable on your system, a shell script, Python code, etc.\n",
    "\n",
    "We provide those for the exemplary workflow outlined above as pre-compiled binaries. Their source code doesn't really\n",
    "matter. If you are interested, you can find the source code under the `data` directory.\n",
    "\n",
    "### `Computer`s and `Code`s\n",
    "\n",
    "Now, before we can start running stuff with AiiDA, we must first register the computational resources and executables we\n",
    "want to use for that purpose.\n",
    "\n",
    "The `verdi presto` command with which we created our profile automatically set up your local workstation as the\n",
    "`localhost` computer, which will suffice for this tutorial. To set up additional `Computer`s in the future,\n",
    "e.g. remote HPC resources, they will need to be registered in AiiDA, providing the necessary SSH and scheduler options.\n",
    "For further information, we refer to the [relevant section of the\n",
    "documentation](https://aiida.readthedocs.io/projects/aiida-core/en/stable/howto/run_codes.html#how-to-set-up-a-computer).\n",
    "Configuration files for some (mainly Swiss) HPC resources [here](https://github.com/aiidateam/aiida-code-registry) (PRs\n",
    "welcome!).\n",
    "\n",
    "We have now finally arrived at some Python code, so let's import the necessary modules, importantly the AiiDA ORM and engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from aiida import orm\n",
    "from aiida.common.exceptions import NotExistent\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_codes = [\n",
    "    {\n",
    "        'label': 'remote_query',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/remote_query.py').resolve()),\n",
    "        'description': 'Python code to query a remote resource and obtain matrix data.'\n",
    "    },\n",
    "    {\n",
    "        'label': 'diagonalization',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/bin/default/diag').resolve()),\n",
    "        'description': 'External executable that can diagonalize a matrix.'\n",
    "    },\n",
    "    {\n",
    "        'label': 'plotting',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/plot_eigvals.py').resolve()),\n",
    "        'description': 'Python script to plot the eigenvalues of the matrix diagonalization.'\n",
    "    }\n",
    "]\n",
    "\n",
    "loaded_codes = []\n",
    "\n",
    "for required_code in required_codes:\n",
    "    code_label = required_code['label']\n",
    "    code_path = required_code['path']\n",
    "    code_description = required_code['description']\n",
    "    \n",
    "    try:\n",
    "        code = orm.load_code(f'{code_label}@localhost')\n",
    "        print(f\"Loaded {code_label}\")\n",
    "    except NotExistent:\n",
    "        code = orm.InstalledCode(\n",
    "            computer=orm.load_computer('localhost'),\n",
    "            filepath_executable=code_path,\n",
    "            label=code_label,\n",
    "            description=code_description,\n",
    "            default_calc_job_plugin='core.shell',\n",
    "            prepend_text='export OMP_NUM_THREADS=1',\n",
    "            append_text='',\n",
    "            use_double_quotes=False,\n",
    "            with_mpi=False\n",
    "        ).store()\n",
    "        print(f\"Created and stored {code_label}\")\n",
    "    loaded_codes.append(code)\n",
    "\n",
    "query_code = loaded_codes[0]\n",
    "diag_code = loaded_codes[1]\n",
    "plot_code = loaded_codes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Code` in AiiDA, various settings are required:\n",
    "\n",
    "- First, the `Computer` where the code should be executed needs to be specified\n",
    "- The absolute path to the executable must be given, as well, and we have already added the correct path for the nanoHUB deployment\n",
    "- A label (to load the `Code` later on), and a description (optional) are also given\n",
    "- The interface how AiiDA interacts with the given executable\n",
    "- In addition, `append_text` and `prepend_text` can be added, and will appear in the submission script before and after\n",
    "  the actual call to the executable. This can be useful to load modules or set environment variables (as done here to\n",
    "  disable hyperthreading)\n",
    "- Lastly, Let's keep things simple and serial by disabling MPI via `with_mpi=False`\n",
    "\n",
    "Note that AiiDA's `verdi` command-line interface (CLI) is often used to set up a `Code` instance for a profile. To this end, the command:\n",
    "\n",
    "```shell\n",
    "verdi code create core.code.installed\n",
    "```\n",
    "\n",
    "needs to be run on the terminal and will ask you for all required options.\n",
    "\n",
    "For convenience, it is also possible to provide these options via a YAML configuration file using the `--config` flat,\n",
    "which can point either to a local file, or to a URL (e.g. on GitHub). The YAML configuration for our `remote_query`\n",
    "executable could have the following content:\n",
    "\n",
    "```yaml\n",
    "append_text: ''\n",
    "computer: localhost\n",
    "default_calc_job_plugin: core.shell\n",
    "description: ''\n",
    "filepath_executable: <absolute-path-to-remote_query>\n",
    "label: remote_query\n",
    "prepend_text: ''\n",
    "use_double_quotes: 'False'\n",
    "with_mpi: 'False'\n",
    "```\n",
    "\n",
    "After creating our `Code`, we can then see if everything works fine by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi code test remote_query\n",
    "%verdi code test diagonalization\n",
    "%verdi code test plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully registered our codes, let's see how we can execute them through `aiida-shell`. For this\n",
    "purpose, we load the `launch_shell_job` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_shell import launch_shell_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To which we pass:\n",
    "\n",
    "- The loaded `Code` that we want to execute, and\n",
    "- The two required command line arguments, namely\n",
    "  - The path to the mocked external database from which we want to obtain data, and\n",
    "  - The matrix identifier (feel free to change that to a value between 0 and 100 to obtain different results)\n",
    "- Lastly, we also specify the output filename of the file that our executable will create (note that `stdout` and\n",
    "  `stderr` are automatically captured by `aiida-shell`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())\n",
    "matrix_pk = 0\n",
    "matrix_file = f'matrix-{matrix_pk}.npy'\n",
    "\n",
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    query_code,\n",
    "    arguments=f'{db_path} {matrix_pk}',\n",
    "    outputs=[matrix_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was simple, wasn't it?\n",
    "\n",
    "Now, `aiida-shell` allows us to pass the output of one job as the input of another job, so let's do that for the next\n",
    "step, and then unpack it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Diagonalize \n",
    "\n",
    "eigvals_file = f'matrix-{matrix_pk}-eigvals.txt'\n",
    "matrix_file_link_label = ShellParser.format_link_label(matrix_file)\n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    diag_code,\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[matrix_file_link_label]\n",
    "    },\n",
    "    outputs = [eigvals_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plotting of the script\n",
    "\n",
    "plot_type = 'violin'\n",
    "figure_file = f'matrix-{matrix_pk}-eigvals-{plot_type}.png'\n",
    "eigvals_file_link_label = ShellParser.format_link_label(eigvals_file)\n",
    "\n",
    "plot_results, plot_node = launch_shell_job(\n",
    "    plot_code,\n",
    "    arguments='-i {eigenval_txt} -p {plot_type}',\n",
    "    nodes={\n",
    "        'eigenval_txt': diag_results[eigvals_file_link_label],\n",
    "        'plot_type': orm.Str(plot_type)\n",
    "    },\n",
    "    outputs = [figure_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi process list -ap 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally while waiting, executing the command above will show processes in various states, for example first you would see this step by order:\n",
    "\n",
    "```bash \n",
    "# Step 1\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  1s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: upload \n",
    "\n",
    "# Step 2\n",
    " PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  2s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: submit\n",
    "\n",
    "# Step 3\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------   \n",
    "6  3s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state QUEUED\n",
    "\n",
    "# Step 4\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  4s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state RUNNING\n",
    "\n",
    "# Step 5\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  5s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: retrieve\n",
    "\n",
    "# Step 6\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  6s ago    ShellJob<remote_query@localhost>          ⏹ Finished [0]\n",
    "```\n",
    "\n",
    "During this tutorial, processes will always be in the `Finished [0]` state, as without the RabbitMQ dependency, we\n",
    "cannot `submit` them to the daemon in a non-blocking manner, but instead `run` them blockingly in the notebook cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all processes have (hopefully) finished successfully, we can visualize the final plotted result, as well as the\n",
    "provenance graph that AiiDA has created from the execution of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use the ShellJob node plot_results\n",
    "display(Image(filename=Path(plot_node.get_remote_workdir()) / figure_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_graph(plot_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Interlude: More `verdi` commands\n",
    "\n",
    "AiiDA provides many useful `verdi` commands to interact with your processes and data. Some of which are listed in the\n",
    "[AiiDA cheatsheet](https://aiida.readthedocs.io/projects/aiida-core/en/stable/reference/cheatsheet.html).\n",
    "\n",
    "As you've seen, `verdi process list -a` shows you all processes (optionally including a time filter with `-p` for *past-days*).\n",
    "\n",
    "The command:\n",
    "\n",
    "```shell\n",
    "verdi calcjob gotocomputer <pk>\n",
    "```\n",
    "\n",
    "will take you the working directory of the process with the pk `<pk>` (performing a `cd` command if you run locally, and\n",
    "ssh-ing into the remote computer if you run remotely).\n",
    "\n",
    "Alternatively, to extract all the files involved in the execution of a workflow to your local disk, you can run:\n",
    "```shell\n",
    "verdi process dump <pk>\n",
    "```\n",
    "\n",
    "Remember to replace <pk> with the actual `pk` of your process. E.g. for the `diagonalization` task from above, you will\n",
    "see that a new folder named `dump-ShellJob<diagonalization@localhost>-<pk>` will be created in the current working\n",
    "directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom parsing of your results\n",
    "\n",
    "When running your matrix diagonalization, you might not want to only obtain the output file with the eigenvalues, but\n",
    "actually retrieve them as Python objects, so that you can the directly operate on them. This can be achieved in\n",
    "`aiida-shell` by attaching a custom parser, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    query_code,\n",
    "    arguments=f'{db_path} {matrix_pk}',\n",
    "    outputs=[matrix_file]\n",
    ")\n",
    "\n",
    "# Custom parser defined that actually reads the created output file and returns the eigenvalues as an AiiDA data type\n",
    "\n",
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "# 2. Run matrix diagonalization with the parser attached\n",
    "\n",
    "eigvals_file = f'matrix-{matrix_pk}-eigvals.txt'\n",
    "matrix_file_link_label = ShellParser.format_link_label(matrix_file)\n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    diag_code,\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[matrix_file_link_label]\n",
    "    },\n",
    "    outputs = [eigvals_file],\n",
    "    parser=parse_array,  # Parser attached here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now seen how we can parse and access the results of our `ShellJob`. This will become important in the next\n",
    "notebook where we'll start creating more complex workflows. So let's go :fire:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
