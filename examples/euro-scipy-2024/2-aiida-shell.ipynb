{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to quickly create a workflow from a set of executables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly set up a running instance\n",
    "\n",
    "### Interacting with AiiDA\n",
    "\n",
    "AiiDA can be controlled in two ways:\n",
    "\n",
    "1. Using the `verdi` command line interface (CLI), or `%verdi` magic in Jupyter notebooks.\n",
    "2. Using the `aiida` Python API\n",
    "\n",
    "For each project in AiiDA, we set up a **profile**, which defines the connection to the data storage (SQLite or PostgreSQL database and file repository), configuration, and other settings.\n",
    "\n",
    "### Creating a profile\n",
    "\n",
    "As of AiiDA **v2.6.1** which was released on 2024-07-01, it is now also possible to create a profile without the\n",
    "PostgreSQL and RabbitMQ services mentioned in the beginning. For the sake of this tutorial, we will use this simplified\n",
    "version, and we refer you to the [installation instructions on\n",
    "RTD](https://aiida.readthedocs.io/projects/aiida-core/en/stable/installation/index.html) for more information on how to\n",
    "set up a fully functional high-performance profile.\n",
    "\n",
    "For setting up our profile, we just need to run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/apps/share64/debian10/anaconda/anaconda-7/envs/AIIDA/bin/verdi presto --profile-name euro-scipy-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created a profile, for convenience, we will now load the AiiDA jupyter extension. This will allow us\n",
    "to use the `%verdi` jupyter magic commands, rather than having to run them in a subshell with the full, absolute\n",
    "path to the `verdi` executable as done in the cell above.\n",
    "\n",
    "In addition, this makes the `%aiida` jupyter magic command available that, when executed, will automatically load the\n",
    "previously created `euro-scipy-2024` default profile. Alternatively, a specific profile can also be loaded as follows:\n",
    "```python\n",
    "from aiida import load_profile\n",
    "load_profile('euro-scipy-2024')\n",
    "```\n",
    "which is the typical way to load a profile and what you will see in most code snippets on the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aiida extension is already loaded. To reload it, use:\n",
      "  %reload_ext aiida\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "current_state": "Loaded AiiDA DB environment - profile name: euro-scipy-2024."
      },
      "text/html": [
       "<p>Loaded AiiDA DB environment - profile name: euro-scipy-2024.</p>"
      ],
      "text/latex": [
       "Loaded AiiDA DB environment - profile name: euro-scipy-2024.\n"
      ],
      "text/plain": [
       "Loaded AiiDA DB environment - profile name: euro-scipy-2024.\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set a some configuration options for our profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mSuccess: \u001b[0m\u001b[22m'warnings.development_version' set to False globally\u001b[0m\n",
      "\u001b[32m\u001b[1mSuccess: \u001b[0m\u001b[22m'warnings.showdeprecations' set to False for 'euro-scipy-2024' profile\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%verdi config set warnings.development_version false\n",
    "%verdi config set warnings.showdeprecations false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And verify that the profile was created successfully via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mversion:     AiiDA v2.6.1\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mconfig:      /home/geiger_j/aiida_projects/fair-workflows-workshop/.aiida\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mprofile:     euro-scipy-2024\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mstorage:     SqliteDosStorage[/home/geiger_j/aiida_projects/fair-workflows-workshop/.aiida/repository/sqlite_dos_19cf4b6c9a8a4e31bd2902ba52fc3e86]: open,\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mbroker:      RabbitMQ v3.9.13 @ amqp://guest:guest@127.0.0.1:5672?heartbeat=600\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/paramiko/transport.py:253: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[22m ⏺ \u001b[0m\u001b[22mdaemon:      The daemon is not running.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should show something like:\n",
    "\n",
    "```shell\n",
    " ✔ version:     AiiDA v2.6.2\n",
    " ✔ config:      /home/nanohub/<your-user>/.aiida\n",
    " ✔ profile:     euro-scipy-2024\n",
    " ✔ storage:     SqliteDosStorage[/home/nanohub/<your-user>/.aiida/repository/sqlite_dos_b25c3582f65647beb068a3e50636a274]: open,\n",
    " ⏺ broker:      No broker defined for this profile: certain functionality not available. See https://aiida-core.readthedocs.io/en/stable/installation/guide_quick.html#quick-install-limitations\n",
    " ⏺ daemon:      No broker defined for this profile: daemon is not available. See {URL_NO_BROKER}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Computer`s and `Code`s\n",
    "\n",
    "The `verdi presto` command used to create the AiiDA profile automatically sets up your local workstation as\n",
    "the `localhost` computer. This will suffice for the sake of the tutorial.\n",
    "\n",
    "To set up additional `Computer`s in the future, e.g. remote HPC resources, they will need to be registered\n",
    "in AiiDA, providing the necessary SSH and scheduler options. For further information, we refer to the [relevant section of the documentation](https://aiida.readthedocs.io/projects/aiida-core/en/stable/howto/run_codes.html#how-to-set-up-a-computer).\n",
    "\n",
    "In a similar manner, executables must be registered in AiiDA, where they are represented as instances of `Code` classes.\n",
    "We will see how we can do this in the following cells where we will set up a multi-step workflow in AiiDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Concatenating several scripts to one workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two tools we will present here for the construction of multi-step workflows through AiiDA are\n",
    "[`aiida-shell`](https://github.com/sphuber/aiida-shell/) and\n",
    "[`aiida-workgraph`](https://github.com/aiidateam/aiida-workgraph/).\n",
    "\n",
    "Both of these tools are set up as external AiiDA plugins and need to be additionally installed. So let's do just that\n",
    "\n",
    "(TODO: Pin version numbers?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/apps/share64/debian10/anaconda/anaconda-7/envs/AIIDA/bin/python -m pip install aiida-shell==0.7.3\n",
    "!/apps/share64/debian10/anaconda/anaconda-7/envs/AIIDA/bin/python -m pip install aiida-workgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these tools don't replace `aiida-core`, but instead provide simplified entry points for workflow creation in\n",
    "AiiDA:\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"../../data/aiida-core-shell-workgraph.jpg\" width=\"800\" style=\"height:auto; display:block; margin-left:auto;\n",
    "margin-right:auto;\">\n",
    "\n",
    "For more in-depth information on how to write AiiDA workflows in the *classical* way, that is, by writing a custom\n",
    "`WorkChain` class, we refer the interested reader to the [relevant documentation\n",
    "section](https://aiida.readthedocs.io/projects/aiida-core/en/latest/howto/write_workflows.html), as well as material from [past AiiDA virtual tutorials](https://aiida-tutorials.readthedocs.io/en/latest/sections/writing_workflows/index.html).\n",
    "\n",
    "Lastly, it is important to note that, while the `aiida-shell` API has been quite stable for a while, the\n",
    "`aiida-workgraph` is still very much under active development. So any feedback you might have during this tutorial will\n",
    "be very valuable to us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workflow setup\n",
    "\n",
    "Assume we would like to execute a workflow that is composed of the following steps:\n",
    "\n",
    "- 1. Create a database that contains some matrices \n",
    "- 2. Run a code that achieves matrix diagonalizations and writes the eigenvalues and eigenvectors to files on disk\n",
    "- 3. Postprocessing, e.g. clean up any intermediate files (JG: not too happy about that, possibly we could do plotting or sthg similar) \n",
    "\n",
    "Naturally, for this tutorial, the example serves mainly demonstration purposes. However, to motivate our choices of\n",
    "tasks, one could imagine the following concrete use cases:\n",
    "\n",
    "- 1. Query and download atomic structures from a materials database via their API\n",
    "- 2. Run structure optimizations using Quantum Mechanical codes (these, like many other numerical codes, run matrix diagonalizations)\n",
    "- 3. Raw output files from the previous steps might be too large (terrabytes) to be retrieved, so postprocessing and\n",
    "     cleanup might be necessary\n",
    "\n",
    "Note that AiiDA was originally created for materials science applications, so we are aware that the examples reflect\n",
    "that. If you think of other use cases, feel free to implement them after this tutorial and let us know about it :star: \n",
    "\n",
    "Each of these steps can be of arbitrary nature, e.g. an executable on your system, a shell script, Python code, etc.\n",
    "\n",
    "We provide those for the exemplary workflow outlined above as pre-compiled binaries. Their source code doesn't really\n",
    "matter. If you are interested, you can still find the source code under the `data` directory.\n",
    "\n",
    "As mentioned above, to run executables through AiiDA, we must fist register them. We can now do that through the Python\n",
    "API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from aiida import orm, engine\n",
    "from aiida.common.exceptions import NotExistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded remote_query\n"
     ]
    }
   ],
   "source": [
    "query_code_label = 'remote_query'\n",
    "query_code_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote_query.py').resolve())\n",
    "\n",
    "try:\n",
    "    query_code = orm.load_code(f'{query_code_label}@localhost')  # The computer label can also be omitted here\n",
    "    print(f\"Loaded {query_code_label}\")\n",
    "except NotExistent:\n",
    "    query_code = orm.InstalledCode(\n",
    "        computer=orm.load_computer('localhost'),\n",
    "        filepath_executable=query_code_path,\n",
    "        label=query_code_label,\n",
    "        description='Python code to query a remote resource and obtain matrix data.',\n",
    "        default_calc_job_plugin='core.shell',\n",
    "        prepend_text='export OMP_NUM_THREADS=1',\n",
    "        append_text='',\n",
    "        use_double_quotes=False,\n",
    "        with_mpi=False\n",
    "    ).store()\n",
    "    print(f\"Created and stored {query_code_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded diagonalization\n"
     ]
    }
   ],
   "source": [
    "diag_code_label = 'diagonalization'\n",
    "diag_code_path = str(Path('../../data/euro-scipy-2024/diag-wf/diager-rs/x86_64-unknown-linux-gnu/diager-rs').resolve())\n",
    "\n",
    "try:\n",
    "    diag_code = orm.load_code(f'{diag_code_label}@localhost')  # The computer label can also be omitted here\n",
    "    print(f\"Loaded {diag_code_label}\")\n",
    "except NotExistent:\n",
    "    diag_code = orm.InstalledCode(\n",
    "        computer=orm.load_computer('localhost'),\n",
    "        filepath_executable=diag_code_path,\n",
    "        label=diag_code_label,\n",
    "        description='',\n",
    "        default_calc_job_plugin='core.shell',\n",
    "        prepend_text='export OMP_NUM_THREADS=1',\n",
    "        append_text='',\n",
    "        use_double_quotes=False,\n",
    "        with_mpi=False\n",
    "    ).store()\n",
    "    print(f\"Created and stored {diag_code_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add section on other ways to set up `Code`s from FAIR workflows notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_shell import launch_shell_job\n",
    "\n",
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())\n",
    "\n",
    "# ? 1. Query a remote database for data\n",
    "\n",
    "matrix_pk = 0\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    query_code,\n",
    "    arguments=f'{db_path} {matrix_pk}',\n",
    "    outputs=[f'{matrix_pk}.npy']\n",
    ")\n",
    "\n",
    "# ? 2. Diagonalize \n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    diag_code,\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[f'aiida_shell_{matrix_pk}_npy']\n",
    "    },\n",
    "    outputs = [f'{matrix_pk}-eigenvals.txt']\n",
    ")\n",
    "\n",
    "# ? 3. Plotting of the script\n",
    "\n",
    "# plot_results, plot_node = launch_shell_job(\n",
    "#     plot_script,\n",
    "#     arguments='{pap_csv}',\n",
    "#     nodes={\n",
    "#         'pap_csv': count_results['pain_and_pleasure_csv']\n",
    "#     },\n",
    "#     outputs = ['pain_and_pleasure.png']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitioning from running locally to submitting remote jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart from the last checkpoint and caching functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and querying your results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
