{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to quickly create a workflow from a set of executables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly set up a running instance\n",
    "\n",
    "### Interacting with AiiDA and creating a profile\n",
    "\n",
    "While AiiDA is already installed in the conda kernel of this deployment, for each project one must set up a **profile**,\n",
    "which defines the connection to the data storage (SQLite or PostgreSQL database and file repository), configuration, and\n",
    "other settings.\n",
    "\n",
    "Overall, AiiDA can be controlled in two ways:\n",
    "\n",
    "1. Using the `verdi` command line interface (CLI), or `%verdi` magic in Jupyter notebooks.\n",
    "2. Using the `aiida` Python API\n",
    "\n",
    "As of AiiDA **v2.6.1** which was released on 2024-07-01, it is now possible to create a profile without the\n",
    "PostgreSQL and RabbitMQ services mentioned previously. For the sake of this tutorial, we will use this simplified\n",
    "version, and we refer you to the [installation instructions on\n",
    "RTD](https://aiida.readthedocs.io/projects/aiida-core/en/stable/installation/index.html) for more information on how to\n",
    "set up a fully functional high-performance profile.\n",
    "\n",
    "To set up our profile, we just need to run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/apps/share64/debian10/anaconda/anaconda-7/envs/AIIDA/bin/verdi presto --profile-name euro-scipy-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created a profile, for convenience, we will now load the AiiDA jupyter extension. This will allow us\n",
    "to use the `%verdi` jupyter magic commands, rather than having to run them in a subshell with the full, absolute\n",
    "path to the `verdi` executable as done in the cell above.\n",
    "\n",
    "In addition, this makes the `%aiida` jupyter magic command available that, when executed, will automatically load the\n",
    "previously created `euro-scipy-2024` default profile. Alternatively, a specific profile can also be loaded as follows:\n",
    "```python\n",
    "from aiida import load_profile\n",
    "load_profile('euro-scipy-2024')\n",
    "```\n",
    "which is the typical way to load a profile and what you will see in most code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "current_state": "Loaded AiiDA DB environment - profile name: presto-3."
      },
      "text/html": [
       "<p>Loaded AiiDA DB environment - profile name: presto-3.</p>"
      ],
      "text/latex": [
       "Loaded AiiDA DB environment - profile name: presto-3.\n"
      ],
      "text/plain": [
       "Loaded AiiDA DB environment - profile name: presto-3.\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set some configuration options for our profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mSuccess: \u001b[0m\u001b[22m'warnings.development_version' set to False globally\u001b[0m\n",
      "\u001b[32m\u001b[1mSuccess: \u001b[0m\u001b[22m'warnings.showdeprecations' set to False for 'presto-3' profile\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%verdi config set warnings.development_version false\n",
    "%verdi config set warnings.showdeprecations false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And verify that the profile was created successfully via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mversion:     AiiDA v2.6.2\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mconfig:      /Users/alexgo/.aiida\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mprofile:     presto-3\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mstorage:     SqliteDosStorage[/Users/alexgo/.aiida/repository/sqlite_dos_a131f6ed7221480fae581f300190e67b]: open,\u001b[0m\n",
      "\u001b[93m\u001b[1mWarning\u001b[0m: RabbitMQ v3.13.6 is not supported and will cause unexpected problems!\n",
      "\u001b[93m\u001b[1mWarning\u001b[0m: It can cause long-running workflows to crash and jobs to be submitted multiple times.\n",
      "\u001b[93m\u001b[1mWarning\u001b[0m: See https://github.com/aiidateam/aiida-core/wiki/RabbitMQ-version-to-use for details.\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mbroker:      RabbitMQ v3.13.6 @ amqp://guest:guest@127.0.0.1:5672?heartbeat=600\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mdaemon:      Daemon is running with PID 26513\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexgo/miniconda3/envs/euroscipy-aiida-demo/lib/python3.10/site-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/Users/alexgo/miniconda3/envs/euroscipy-aiida-demo/lib/python3.10/site-packages/paramiko/transport.py:253: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    }
   ],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should show something like:\n",
    "\n",
    "```shell\n",
    " ✔ version:     AiiDA v2.6.2\n",
    " ✔ config:      /home/nanohub/<your-user>/.aiida\n",
    " ✔ profile:     euro-scipy-2024\n",
    " ✔ storage:     SqliteDosStorage[/home/nanohub/<your-user>/.aiida/repository/sqlite_dos_b25c3582f65647beb068a3e50636a274]: open,\n",
    " ⏺ broker:      No broker defined for this profile: certain functionality not available. See https://aiida-core.readthedocs.io/en/stable/installation/guide_quick.html#quick-install-limitations\n",
    " ⏺ daemon:      No broker defined for this profile: daemon is not available. See {URL_NO_BROKER}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Concatenating several scripts to one workflow\n",
    "\n",
    "### The workflow setup\n",
    "\n",
    "Now that we have a working profile set up, assume we would like to execute a workflow that is composed of the following\n",
    "steps:\n",
    "\n",
    "- 1. Create a database that contains some matrices \n",
    "- 2. Run a code that achieves matrix diagonalizations and writes the eigenvalues and eigenvectors to files on disk\n",
    "- 3. Plot the results from the previous steps\n",
    "\n",
    "For this tutorial, the chosen example serves mainly demonstration purposes. However, to motivate our choices of\n",
    "tasks, one could imagine the following concrete use cases:\n",
    "\n",
    "- 1. Query and download atomic structures from a materials database via their API\n",
    "- 2. Run structure optimizations using Quantum Mechanical codes like QE (these, like many other numerical codes, run\n",
    "     many matrix diagonalizations)\n",
    "- 3. Visualize our results for a scientific publication\n",
    "\n",
    "Note that AiiDA was originally created for materials science applications, so we are aware that the examples reflect\n",
    "that. If you think of other use cases, feel free to implement them after this tutorial and let us know about them :star: \n",
    "\n",
    "Each of the steps of our workflow can be of arbitrary nature, e.g. an executable on your system, a shell script, Python code, etc.\n",
    "\n",
    "We provide those for the exemplary workflow outlined above as pre-compiled binaries. Their source code doesn't really\n",
    "matter. If you are interested, you can find the source code under the `data` directory.\n",
    "\n",
    "### `Computer`s and `Code`s\n",
    "\n",
    "Now, before we can start running stuff with AiiDA, we must first register the computational resources and executables we\n",
    "want to use for that purpose.\n",
    "\n",
    "The `verdi presto` command with which we created our profile automatically set up your local workstation as the\n",
    "`localhost` computer, which will suffice for this tutorial. To set up additional `Computer`s in the future,\n",
    "e.g. remote HPC resources, they will need to be registered in AiiDA, providing the necessary SSH and scheduler options.\n",
    "For further information, we refer to the [relevant section of the\n",
    "documentation](https://aiida.readthedocs.io/projects/aiida-core/en/stable/howto/run_codes.html#how-to-set-up-a-computer).\n",
    "Configuration files for some (mainly Swiss) HPC resources [here](https://github.com/aiidateam/aiida-code-registry) (PRs\n",
    "welcome!).\n",
    "\n",
    "We have now finally arrived at some Python code, so let's import the necessary modules, importantly the AiiDA ORM and engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from aiida import orm\n",
    "from aiida.common.exceptions import NotExistent\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and stored remote_query\n",
      "Created and stored diagonalization\n",
      "Created and stored plotting\n"
     ]
    }
   ],
   "source": [
    "required_codes = [\n",
    "    {\n",
    "        'label': 'remote_query',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/remote_query.py').resolve()),\n",
    "        'description': 'Python code to query a remote resource and obtain matrix data.'\n",
    "    },\n",
    "    {\n",
    "        'label': 'diagonalization',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/bin/default/diag').resolve()),\n",
    "        'description': 'External executable that can diagonalize a matrix.'\n",
    "    },\n",
    "    {\n",
    "        'label': 'plotting',\n",
    "        'path': str(Path('../../data/euro-scipy-2024/diag-wf/plot_eigenvals.py').resolve()),\n",
    "        'description': 'Python script to plot the eigenvalues of the matrix diagonalization.'\n",
    "    }\n",
    "]\n",
    "\n",
    "loaded_codes = []\n",
    "\n",
    "for required_code in required_codes:\n",
    "    code_label = required_code['label']\n",
    "    code_path = required_code['path']\n",
    "    code_description = required_code['description']\n",
    "    \n",
    "    try:\n",
    "        code = orm.load_code(f'{code_label}@localhost')\n",
    "        print(f\"Loaded {code_label}\")\n",
    "    except NotExistent:\n",
    "        code = orm.InstalledCode(\n",
    "            computer=orm.load_computer('localhost'),\n",
    "            filepath_executable=code_path,\n",
    "            label=code_label,\n",
    "            description=code_description,\n",
    "            default_calc_job_plugin='core.shell',\n",
    "            prepend_text='export OMP_NUM_THREADS=1',\n",
    "            append_text='',\n",
    "            use_double_quotes=False,\n",
    "            with_mpi=False\n",
    "        ).store()\n",
    "        print(f\"Created and stored {code_label}\")\n",
    "    loaded_codes.append(code)\n",
    "\n",
    "query_code = loaded_codes[0]\n",
    "diag_code = loaded_codes[1]\n",
    "plot_code = loaded_codes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Code` in AiiDA, various settings are required:\n",
    "\n",
    "- First, the `Computer` where the code should be executed needs to be specified\n",
    "- The absolute path to the executable must be given, as well, and we have already added the correct path for the nanoHUB deployment\n",
    "- A label (to load the `Code` later on), and a description (optional) are also given\n",
    "- The interface how AiiDA interacts with the given executable\n",
    "- In addition, `append_text` and `prepend_text` can be added, and will appear in the submission script before and after\n",
    "  the actual call to the executable. This can be useful to load modules or set environment variables (as done here to\n",
    "  disable hyperthreading)\n",
    "- Lastly, Let's keep things simple and serial by disabling MPI via `with_mpi=False`\n",
    "\n",
    "Note that AiiDA's `verdi` command-line interface (CLI) is often used to set up a `Code` instance for a profile. To this end, the command:\n",
    "\n",
    "```shell\n",
    "verdi code create core.code.installed\n",
    "```\n",
    "\n",
    "needs to be run on the terminal and will ask you for all required options.\n",
    "\n",
    "For convenience, it is also possible to provide these options via a YAML configuration file using the `--config` flat,\n",
    "which can point either to a local file, or to a URL (e.g. on GitHub). The YAML configuration for our `remote_query`\n",
    "executable could have the following content:\n",
    "\n",
    "```yaml\n",
    "append_text: ''\n",
    "computer: localhost\n",
    "default_calc_job_plugin: core.shell\n",
    "description: ''\n",
    "filepath_executable: <absolute-path-to-remote_query>\n",
    "label: remote_query\n",
    "prepend_text: ''\n",
    "use_double_quotes: 'False'\n",
    "with_mpi: 'False'\n",
    "```\n",
    "\n",
    "After creating our `Code`, we can then see if everything works fine by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi code test remote_query\n",
    "%verdi code test diagonalization\n",
    "%verdi code test plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully registered our codes, let's see how we can execute them through `aiida-shell`. For this\n",
    "purpose, we load the `launch_shell_job` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_shell import launch_shell_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To which we pass:\n",
    "\n",
    "- The loaded `Code` that we want to execute, and\n",
    "- The two required command line arguments, namely\n",
    "  - The path to the mocked external database from which we want to obtain data, and\n",
    "  - The matrix identifier (feel free to change that to a value between 0 and 100 to obtain different results)\n",
    "- Lastly, we also specify the output filename of the file that our executable will create (note that `stdout` and\n",
    "  `stderr` are automatically captured by `aiida-shell`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWarning\u001b[0m: output parser returned exit code<303>: One or more output files defined in the `outputs` input were not retrieved: matrix-0.npy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:aiida.orm.nodes.process.calculation.calcjob.CalcJobNode:output parser returned exit code<303>: One or more output files defined in the `outputs` input were not retrieved: matrix-0.npy.\n"
     ]
    }
   ],
   "source": [
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())\n",
    "matrix_pk = 0\n",
    "\n",
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    query_code,\n",
    "    arguments=f'{db_path} {matrix_pk}',\n",
    "    outputs=[f'matrix-{matrix_pk}.npy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was simple, wasn't it?\n",
    "\n",
    "Now, `aiida-shell` allows us to pass the output of one job as the input of another job, so let's do that for the next\n",
    "step, and then unpack it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Diagonalize \n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    diag_code,\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[f'matrix_{matrix_pk}_npy']\n",
    "    },\n",
    "    outputs = [f'matrix-{matrix_pk}-eigvals.txt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plotting of the script\n",
    "\n",
    "plot_type = 'violin'\n",
    "figure_name = f'matrix-{matrix_pk}-eigvals-{plot_type}.png'\n",
    "\n",
    "plot_results, plot_node = launch_shell_job(\n",
    "    plot_code,\n",
    "    arguments='-i {eigenval_txt} -p {plot_type}',\n",
    "    nodes={\n",
    "        'eigenval_txt': diag_results[f'matrix_{matrix_pk}_eigvals_txt'],\n",
    "        'plot_type': orm.Str(plot_type)\n",
    "    },\n",
    "    outputs = [figure_name]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi process list -ap 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally while waiting, exectuting the command above will show all process state at each step, for example first you would see this step by order:\n",
    "\n",
    "```bash \n",
    "# Step 1\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  1s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: upload \n",
    "\n",
    "# Step 2\n",
    " PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  2s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: submit\n",
    "\n",
    "# Step 3\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------   \n",
    "6  3s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state QUEUED\n",
    "\n",
    "# Step 4\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  4s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state RUNNING\n",
    "\n",
    "# Step 5\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  5s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: retrieve\n",
    "\n",
    "# Step 6\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  6s ago    ShellJob<remote_query@localhost>          ⏹ Finished [0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use the ShellJob node plot_results\n",
    "display(Image(filename=Path(plot_node.get_remote_workdir()) / figure_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.tools.visualization import Graph\n",
    "graph = Graph()\n",
    "graph.recurse_ancestors(plot_node, annotate_links=\"both\")\n",
    "graph.recurse_descendants(plot_node, annotate_links=\"both\")\n",
    "graph.graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### More from verdi tool\n",
    "\n",
    "The following command will take you the working directory, performing a `cd` operation on your file. Just take the `pk` of process you want to check it's files.\n",
    "\n",
    "`verdi process list -a`\n",
    "\n",
    "`verdi calcjob gotocomputer <pk>`\n",
    "\n",
    "Alternatively, to obtain all the files in the workflow in an arbitrary location, do the following. \n",
    "Remember to replace <pk> with the `pk` of your prccess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi process dump <pk>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will see, that a new folder is named `dump-ShellJob<diagonalization@localhost>-<pk>` is created in the current working directory.\n",
    "\n",
    "\n",
    "For more of `verdi` command line please check [verdi cheatsheet](https://aiida.readthedocs.io/projects/aiida-core/en/stable/reference/cheatsheet.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart from the last checkpoint and caching functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and querying your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())\n",
    "matrix_pk = 0\n",
    "\n",
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    query_code,\n",
    "    arguments=f'{db_path} {matrix_pk}',\n",
    "    outputs=[f'matrix-{matrix_pk}.npy']\n",
    ")\n",
    "\n",
    "def parse_array(self, dirpath: pathlib.Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {'eigvals': data}\n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    diag_code,\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[f'matrix_{matrix_pk}_npy']\n",
    "    },\n",
    "    outputs = [f'matrix-{matrix_pk}-eigvals.txt']\n",
    "    parser = parse_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO querying maybe present in WG notebook because we have more data available after the for loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
