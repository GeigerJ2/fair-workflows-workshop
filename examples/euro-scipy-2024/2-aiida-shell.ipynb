{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to quickly create a workflow from a set of executables\n",
    "\n",
    "**Please note, this notebook depends on successful execution of the first notebook `1-aiida-intro.ipynb`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Concatenating several scripts to one workflow\n",
    "\n",
    "### The workflow setup\n",
    "\n",
    "Now that we have a working profile set up, assume we would like to execute a workflow that is composed of the following\n",
    "steps:\n",
    "\n",
    "- 1. Query a database that contains some matrices \n",
    "- 2. Run a code that achieves matrix diagonalizations and writes the eigenvalues and eigenvectors to files on disk\n",
    "- 3. Plot the obtained eigenvalues from the previous steps\n",
    "\n",
    "Each of the steps of our workflow can be of arbitrary nature, e.g. an executable on your system, a shell script, Python code, etc. We provide those for the exemplary workflow outlined above as pre-compiled binaries. Their source code doesn't really\n",
    "matter. If you are interested, you can find the source code under the `data` directory.\n",
    "\n",
    "<img src=\"../../data/figs/dummy-workflow.png\" width=\"400\" style=\"height:auto; display:block; margin-left:auto;\n",
    "margin-right:auto;\">\n",
    "\n",
    "Now, let's import the necessary modules, importantly the AiiDA ORM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:11.519473Z",
     "start_time": "2024-08-26T10:19:11.510640Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from aiida import orm\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:11.915361Z",
     "start_time": "2024-08-26T10:19:11.842073Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:12.248749Z",
     "start_time": "2024-08-26T10:19:12.240673Z"
    }
   },
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we're ready to run our binaries through `aiida-shell`. They should already be accessible through via the\n",
    "`$PATH`. If not, uncomment these lines to make them available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo 'export PATH=$PATH:$HOME/fair-workflows-workshop/data/euro-scipy-2024/diag-wf/' >> ~/.bash_profile\n",
    "# !echo 'export PATH=$PATH:$HOME/fair-workflows-workshop/data/euro-scipy-2024/diag-wf/bin/default' >> ~/.bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then we load the `launch_shell_job` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:13.601220Z",
     "start_time": "2024-08-26T10:19:13.595225Z"
    }
   },
   "outputs": [],
   "source": [
    "from aiida_shell import launch_shell_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To which we pass:\n",
    "\n",
    "- The codes that we want to execute, which can be, either\n",
    "  - Common binaries available on Linux systems, such as `cat`, `echo`, etc.\n",
    "  - Custom binaries, if they are discoverable e.g. by adding them to `$PATH`\n",
    "  - Full paths to custom binaries (albeit this will lead to long code labels)\n",
    "  - And previously created `Code` instances, already registered in AiiDA\n",
    "- The two required command line arguments, namely\n",
    "  - The path to the mocked external database from which we want to obtain data, and\n",
    "  - The matrix identifier (feel free to change that to a value between 0 and 100 to obtain different results)\n",
    "- Lastly, we also specify the output filename of the file that our executable will create (note that `stdout` and\n",
    "  `stderr` are automatically captured by `aiida-shell`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:17.940220Z",
     "start_time": "2024-08-26T10:19:14.015565Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())\n",
    "matrix_id = 0\n",
    "matrix_file = f'matrix-{matrix_id}.npy'\n",
    "\n",
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    'remote_query.py',\n",
    "    arguments=f'{db_path} {matrix_id}',\n",
    "    outputs=[matrix_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was simple, wasn't it?\n",
    "\n",
    "Now, `aiida-shell` allows us to pass the output of one job as the input of another job, so let's do that for the next\n",
    "step, and then unpack it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:21.402299Z",
     "start_time": "2024-08-26T10:19:18.258459Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Diagonalize \n",
    "\n",
    "eigvals_file = f'matrix-{matrix_id}-eigvals.txt'\n",
    "matrix_file_link_label = ShellParser.format_link_label(matrix_file)\n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    'diag',\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[matrix_file_link_label]\n",
    "    },\n",
    "    outputs = [eigvals_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:27.237681Z",
     "start_time": "2024-08-26T10:19:21.717293Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Plotting of the script\n",
    "\n",
    "plot_type = 'violin'\n",
    "eigvals_file_link_label = ShellParser.format_link_label(eigvals_file)\n",
    "figure_file = f'matrix-{matrix_id}-eigvals-{plot_type}.png'\n",
    "figure_file_link_label = ShellParser.format_link_label(figure_file)\n",
    "\n",
    "plot_results, plot_node = launch_shell_job(\n",
    "    'plot_eigvals.py',\n",
    "    arguments='-i {eigenval_txt} -p {plot_type}',\n",
    "    nodes={\n",
    "        'eigenval_txt': diag_results[eigvals_file_link_label],\n",
    "        'plot_type': orm.Str(plot_type)\n",
    "    },\n",
    "    outputs = [figure_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:27.739311Z",
     "start_time": "2024-08-26T10:19:27.584549Z"
    }
   },
   "outputs": [],
   "source": [
    "%verdi process list -ap 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all processes have (hopefully) finished successfully, we can visualize the final plotted result, as well as the\n",
    "provenance graph that AiiDA has created from the execution of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:28.124520Z",
     "start_time": "2024-08-26T10:19:28.106798Z"
    }
   },
   "outputs": [],
   "source": [
    "with plot_node.outputs[figure_file_link_label].as_path() as filepath:\n",
    "    display(Image(filename=filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:28.591950Z",
     "start_time": "2024-08-26T10:19:28.330311Z"
    }
   },
   "outputs": [],
   "source": [
    "provenance_graph(plot_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally while waiting, executing the command above will show processes in various states, for example first you would see this step by order:\n",
    "\n",
    "```bash \n",
    "# Step 1\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  1s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: upload \n",
    "\n",
    "# Step 2\n",
    " PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  2s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: submit\n",
    "\n",
    "# Step 3\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------   \n",
    "6  3s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state QUEUED\n",
    "\n",
    "# Step 4\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  4s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Monitoring scheduler: job state RUNNING\n",
    "\n",
    "# Step 5\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  5s ago    ShellJob<remote_query@localhost>          ⏵ Waiting        Waiting for transport task: retrieve\n",
    "\n",
    "# Step 6\n",
    "PK  Created    Process label                        ♻    Process State    Process status\n",
    "----  ---------  -----------------------------------  ---  ---------------  ----------------\n",
    "6  6s ago    ShellJob<remote_query@localhost>          ⏹ Finished [0]\n",
    "```\n",
    "\n",
    "During this tutorial, processes will always be in the `Finished [0]` state, as without the RabbitMQ dependency, we\n",
    "cannot `submit` them to the daemon in a non-blocking manner, but instead `run` them blockingly in the notebook cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom parsing of your results\n",
    "\n",
    "When running your matrix diagonalization, you might not want to only obtain the output file with the eigenvalues, but\n",
    "actually retrieve them as Python objects, so that you can the directly operate on them. This can be achieved in\n",
    "`aiida-shell` by attaching a custom parser, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:35.844598Z",
     "start_time": "2024-08-26T10:19:28.856907Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Query a remote database for data\n",
    "\n",
    "query_results, query_node = launch_shell_job(\n",
    "    'remote_query.py',\n",
    "    arguments=f'{db_path} {matrix_id}',\n",
    "    outputs=[matrix_file]\n",
    ")\n",
    "\n",
    "# Custom parser defined that actually reads the created output file and returns the eigenvalues as an AiiDA data type\n",
    "\n",
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "# 2. Run matrix diagonalization with the parser attached\n",
    "\n",
    "eigvals_file = f'matrix-{matrix_id}-eigvals.txt'\n",
    "matrix_file_link_label = ShellParser.format_link_label(matrix_file)\n",
    "\n",
    "diag_results, diag_node = launch_shell_job(\n",
    "    'diag',\n",
    "    arguments='{matrix_file}',\n",
    "    nodes={\n",
    "        'matrix_file': query_results[matrix_file_link_label]\n",
    "    },\n",
    "    outputs = [eigvals_file],\n",
    "    parser=parse_array,  # Parser attached here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:19:36.165766Z",
     "start_time": "2024-08-26T10:19:36.138362Z"
    }
   },
   "outputs": [],
   "source": [
    "print(diag_results['eigvals'])\n",
    "print(diag_results['eigvals'].get_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now seen how we can parse and access the results of our `ShellJob`. This will become important in the next\n",
    "notebook where we'll start creating more complex workflows. So let's go :fire:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (AIIDA)",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
