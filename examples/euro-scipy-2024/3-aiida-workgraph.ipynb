{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create more complex workflows\n",
    "\n",
    "We "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And verify that the profile was created successfully via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Concatenating several scripts to one workflow and more :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from aiida import engine, orm\n",
    "from aiida.common.exceptions import NotExistent\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_shell.parsers import ShellParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_code = orm.load_code('diagonalization@localhost')  # The computer label can also be omitted here\n",
    "query_code = orm.load_code('remote_query@localhost')  # The computer label can also be omitted here\n",
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"query_and_diag\")\n",
    "\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_code,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "\n",
    "def parse_array(self, dirpath: pathlib.Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_code,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This how you retrieve your outputs after a run with WorkGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "diag_task.node.outputs['aiida_shell_5_eigvals_txt']\n",
    "diag_task.node.outputs.eigvals.get_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending WorkGraph with arbitrary python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"compute_eigvals_wg\")\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_task,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "\n",
    "def parse_array(self, dirpath: pathlib.Path) -> dict[str, orm.Data]:\n",
    "    global diag_output_filename\n",
    "    arr = np.loadtxt(dirpath / diag_output_filename)\n",
    "    return {\"eigvals\": orm.ArrayData(arr)}\n",
    "\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_task,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "\n",
    "# Why do you have to wrap your function? So aiida understands your function\n",
    "# Try comment out the code and look at the provenance graph\n",
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "    return orm.Float(np.mean(eigenvalues.get_array()))\n",
    "\n",
    "\n",
    "# plot_task = wg.add_task(\n",
    "#     plot, name=\"plot_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    "# )\n",
    "mean_task = wg.add_task(\n",
    "    compute_mean, name=\"mean_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    ")\n",
    "\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the `compute_mean` result (the orm.Float) is not present in the provenance graph when we remove the calcfunction decorator because it is not stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph.utils import generate_node_graph\n",
    "generate_node_graph(wg.pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can display the image in a similar way by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(wg.tasks[\"plot_task\"].outputs[\"result\"].value)  # SinglefileData\n",
    "with wg.tasks[\"plot_task\"].outputs[\"result\"].value.as_path() as filepath:\n",
    "    display(Image(filename=(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_parser(self, dirpath: pathlib.Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])  # this is small aiida detail\n",
    "    data = orm.ArrayData(arr)\n",
    "    data.attributes[\"length\"] = len(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "\n",
    "@task.graph_builder(\n",
    "    outputs=[\n",
    "        {\"name\": \"eigvals\", \"from\": \"diag_task.eigvals\"},\n",
    "        {\"name\": \"mean_eigval\", \"from\": \"compute_mean.result\"},\n",
    "    ]\n",
    ")\n",
    "def query_and_diag(matrix_pk: orm.Int):\n",
    "    wg = WorkGraph()\n",
    "    query_output_filename = f\"matrix-{matrix_pk.value}.npy\"\n",
    "\n",
    "    query_code = orm.load_code(f\"query@localhost\")\n",
    "    query_task = wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"query_task\",\n",
    "        command=query_code,\n",
    "        arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "        nodes={\n",
    "            \"db_path\": \"/Users/alexgo/code/fair-workflows-workshop/data/euro-scipy-2024/diag-wf/remote/matrices.db\",\n",
    "            \"matrix_pk\": matrix_pk,\n",
    "        },\n",
    "        outputs=[query_output_filename],\n",
    "    )\n",
    "    query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "    diag_output_filename = f\"matrix-{matrix_pk.value}-eigvals.txt\"\n",
    "\n",
    "    diag_code = orm.load_code(f\"diag@localhost\")\n",
    "    wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"diag_task\",\n",
    "        command=diag_code,\n",
    "        arguments=[\"{matrix_file}\"],\n",
    "        parser=array_parser,\n",
    "        nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "        outputs=[diag_output_filename],\n",
    "        parser_outputs=[{\"name\": \"eigvals\"}],\n",
    "    )\n",
    "\n",
    "    @task.calcfunction\n",
    "    def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "        node = orm.Float(np.mean(eigenvalues.get_array()))\n",
    "        node.attributes[\"length\"] = len(eigenvalues)\n",
    "        return node\n",
    "\n",
    "    # TODO add compute_mean\n",
    "\n",
    "    return wg\n",
    "\n",
    "\n",
    "wg = WorkGraph()\n",
    "wg.add_task(query_and_diag)\n",
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "for i in range(1, 5):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to collect all the results and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO you don't have to compute anymore the mean value because it is exposed by the graph_builder\n",
    "@task.calcfunction\n",
    "def assemble_plot(**collected_eigvals) -> dict[str, orm.Data]:\n",
    "    # return orm.List([arr.get_array() for arr in x.values()])\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    label: str\n",
    "    eigval_data: orm.ArrayData\n",
    "    mean_eigenvalues = []\n",
    "    for _, eigval_data in collected_eigvals.items():\n",
    "        mean_eigenvalues.append(np.mean(eigval_data.get_array()))\n",
    "    ax.hist(mean_eigenvalues, bins=10, color=\"c\", edgecolor=\"black\")\n",
    "    ax.set_title(\"Histogram of Eigenvalues\")\n",
    "    ax.set_xlabel(\"Eigenvalue\")\n",
    "    filename = \"plot.jpg\"\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    return orm.SinglefileData(Path(filename).absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "assemble_plot_task = wg.add_task(assemble_plot, name=\"assemble_plot_task\")\n",
    "# we have to increase the link limit because by default workgraph only supports one link per input socket\n",
    "assemble_plot_task.inputs[\"collected_eigvals\"].link_limit = 50\n",
    "for i in range(1, 10):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "    wg.add_link(\n",
    "        query_and_diag_task.outputs[\"eigvals\"],\n",
    "        assemble_plot_task.inputs[\"collected_eigvals\"],\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QueryBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can query now from our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also introduce filters in our queriesS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    filters={\n",
    "        'attributes.length': {'==': 50}\n",
    "    },\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we create if conditions workflows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def compute_mean(eigvals: orm.ArrayData) -> orm.Float:\n",
    "    return orm.Float(np.mean(eigvals.get_array()))\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def eigvals_less(mean_eigval: orm.Float) -> bool:\n",
    "    return mean_eigval < 14.5\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def heureka(eigvals, pk):\n",
    "    try:\n",
    "        path = Path(\"storage\").absolute()\n",
    "        path.mkdir(exist_ok=True)\n",
    "        result_path = path / f\"eigvals-pk{pk}.npy\"\n",
    "        np.save(result_path, eigvals.get_array())\n",
    "        success = orm.Int(0)\n",
    "        success.attributes[\"path\"] = str(result_path)\n",
    "        success.attributes[\"error\"] = \"\"\n",
    "    except Exception as err:\n",
    "        success = orm.Int(1)\n",
    "        success.attributes[\"path\"] = \"\"\n",
    "        success.attributes[\"error\"] = str(err)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"someother\")\n",
    "\n",
    "martix_pk = 5\n",
    "\n",
    "query_and_diag_task = wg.add_task(\n",
    "    query_and_diag, name=f\"query_and_diag_pk{matrix_pk}\", matrix_pk=orm.Int(matrix_pk)\n",
    ")\n",
    "compute_mean_task = wg.add_task(\n",
    "    compute_mean,\n",
    "    name=f\"compute_mean_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    ")\n",
    "eigvals_less_task = wg.add_task(\n",
    "    eigvals_less,\n",
    "    name=f\"eigvals_less_task_pk{matrix_pk}\",\n",
    "    mean_eigval=compute_mean_task.outputs[\"result\"],\n",
    ")\n",
    "if_less = wg.add_task(\n",
    "    \"If\", name=f\"if_less_pk{matrix_pk}\", conditions=eigvals_less_task.outputs[\"result\"]\n",
    ")  # there as specific conditions socket\n",
    "heureka_task = wg.add_task(\n",
    "    heureka,\n",
    "    name=f\"heureka_task_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    "    pk=orm.Int(i),\n",
    ")\n",
    "if_less.children.add(f\"heureka_task_pk{matrix_pk}\")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
