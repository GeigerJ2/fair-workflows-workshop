{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create more complex workflows\n",
    "\n",
    "## Concatenating several scripts to one workflow and more :)\n",
    "\n",
    "In the previous notebook, we have seen how we can run arbitrary executables through `aiida-shell` without requiring any\n",
    "code-specific infrastructure (typically contained in a dedicated AiiDA plugin). In addition, we have seen how we can\n",
    "feed the output of one task to the input of another task, linking the two and effectively creating a workflow.\n",
    "\n",
    "Building on this concept, the `aiida-workgraph` provides the capability to create workflows in the same manner as one would\n",
    "build up an actual graph. That is, by adding nodes and edges to it. It further extends the possible building blocks from\n",
    "external scripts to existing AiiDA buliding blocks (`CalcFunction`s, `CalcJob`s, `WorkChain`s, etc.), as well as custom\n",
    "Python code.\n",
    "\n",
    "We'll cover lots of material in this notebook, so strap yourself in and buckle up! :rocket:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the AiiDA jupyter notebook extension, check the profile status, import the libraries all that we need. So nothing new\n",
    "here, really..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aiida extension is already loaded. To reload it, use:\n",
      "  %reload_ext aiida\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "current_state": "Loaded AiiDA DB environment - profile name: euro-scipy-2024."
      },
      "text/html": [
       "<p>Loaded AiiDA DB environment - profile name: euro-scipy-2024.</p>"
      ],
      "text/latex": [
       "Loaded AiiDA DB environment - profile name: euro-scipy-2024.\n"
      ],
      "text/plain": [
       "Loaded AiiDA DB environment - profile name: euro-scipy-2024.\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mversion:     AiiDA v2.6.1\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mconfig:      /home/geiger_j/aiida_projects/fair-workflows-workshop/.aiida\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mprofile:     euro-scipy-2024\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mstorage:     SqliteDosStorage[/home/geiger_j/aiida_projects/fair-workflows-workshop/.aiida/repository/sqlite_dos_19cf4b6c9a8a4e31bd2902ba52fc3e86]: open,\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mbroker:      RabbitMQ v3.9.13 @ amqp://guest:guest@127.0.0.1:5672?heartbeat=600\u001b[0m\n",
      "\u001b[32m\u001b[22m ✔ \u001b[0m\u001b[22mdaemon:      Daemon is running with PID 1842818\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from aiida import orm\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph\n",
    "\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.utils import generate_node_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_code = orm.load_code('diagonalization@localhost')  # The computer label can also be omitted here\n",
    "query_code = orm.load_code('remote_query@localhost')  # The computer label can also be omitted here\n",
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkGraph vs. provenance graph\n",
    "\n",
    "As evident from the import statement:\n",
    "\n",
    "```python\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "```\n",
    "\n",
    "the first entity we'll be using is, of course, the `WorkGraph`. In addition, we import the `task`, which actually\n",
    "presents the `WorkGraph` equivalent of a *node* in the graphs we'll be building up.\n",
    "\n",
    "In line with common graph nomenclature, we'd have loved to use the **Node** keyword for that, but remember, the `Node`\n",
    "class is already defined in `aiida-core`. To avoid confusion, it is good to mention here, that we will now be talking\n",
    "about two different kinds of graphs:\n",
    "- **The provenance graph**: AiiDA's way of storing the **Data** and **Processes** inside the SQL database as **Node**s\n",
    "  and **Link**\n",
    "- **The WorkGraph**: The workflow we are building up using the `aiida-workgraph` library\n",
    "\n",
    "As such, we can build up our workflow as a **WorkGraph**, run it, and AiiDA will store all data in its database, allowing\n",
    "us to explore the resulting **provenance graph** of our workflow.\n",
    "\n",
    "Let's maybe best start with some simple examples, this will make things clear. We'll close the cycle to the previous\n",
    "notebook in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633dcd482f1d4c67b5d0158df36bd264",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'First W…"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sleep_and_print(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time)\n",
    "    print(print_statement)\n",
    "\n",
    "wg = WorkGraph('First WG')\n",
    "\n",
    "wg.add_task(sleep_and_print)\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you just created your first `WorkGraph`! Let's unpack the code: We first created a very simple Python\n",
    "function, we then instantiated the `WorkGraph`, and added our function as a task (remember, think of *graph nodes*).\n",
    "\n",
    "`aiida-workgraph` comes with a visualization tool in which we can see the setup of our workflow. Note that we didn't\n",
    "actually run it at this point, yet. Let's add a second task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633dcd482f1d4c67b5d0158df36bd264",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'First W…"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.add_task(sleep_and_print)\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we now have two disconnected tasks in our workgraph. To define dependencies between those, we can either\n",
    "link inputs and outpus, just as we did before with `aiida-shell`, or explicitly enforce that the second task has to wait\n",
    "on the first one. For now, let's actually focus on the second case (the first one will require us to introduce a few\n",
    "more concepts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633dcd482f1d4c67b5d0158df36bd264",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'First W…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.tasks.sleep_and_print2.waiting_on.add('sleep_and_print1')\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we accessed the second task through our `WorkGraph` instance, `wg`. However, the `add_task` function\n",
    "actually returns the task, so we can also write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49904efeae054fef9c290ebadcf24d3b",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'First W…"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg = WorkGraph('First WG')\n",
    "\n",
    "task1 = wg.add_task(sleep_and_print)\n",
    "task2 = wg.add_task(sleep_and_print)\n",
    "\n",
    "task2.waiting_on.add('sleep_and_print1')\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which achieves the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Python code with WorkGraph and AiiDA provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we want to actually run our workflow, we should specify some inputs to our tasks. We can do that, as well as name our\n",
    "tasks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18058f6b7d94feabb8a8146a266abb6",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'Run WG'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  lets_start\n",
      "update task state:  lets_continue\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|run_tasks]: Run task: lets_start, type: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|run_tasks]: Run task: lets_start, type: Normal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|set_normal_task_results]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|set_normal_task_results]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: Normal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's continue\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|set_normal_task_results]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|set_normal_task_results]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  lets_start FINISHED\n",
      "task:  lets_continue FINISHED\n",
      "is workgraph finished:  True\n",
      "workgraph outputs:  []\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84855|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84855|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize workgraph Run WG\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'new_data': {},\n",
       " 'execution_count': <Int: uuid: c02ac138-bd3d-4a8d-b76c-422535be2a69 (pk: 84856) value: 0>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg = WorkGraph(\"Run WG\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_continue\", sleep_time=1, print_statement=\"Let's continue\"\n",
    ")\n",
    "\n",
    "task2.waiting_on.add('lets_start')\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like everything worked out smoothly. Now, let's show the provenance graph of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"200pt\" height=\"163pt\"\n",
       " viewBox=\"0.00 0.00 200.00 163.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 159)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-159 196,-159 196,4 -4,4\"/>\n",
       "<!-- N84855 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>N84855</title>\n",
       "<polygon fill=\"#e38851\" stroke=\"red\" stroke-width=\"6\" points=\"192,-155 0,-155 0,-102 192,-102 192,-155\"/>\n",
       "<text text-anchor=\"middle\" x=\"96\" y=\"-139.8\" font-family=\"Times,serif\" font-size=\"14.00\">WorkGraph&lt;Run WG&gt; (84855)</text>\n",
       "<text text-anchor=\"middle\" x=\"96\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">State: finished</text>\n",
       "<text text-anchor=\"middle\" x=\"96\" y=\"-109.8\" font-family=\"Times,serif\" font-size=\"14.00\">Exit Code: 0</text>\n",
       "</g>\n",
       "<!-- N84856 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>N84856</title>\n",
       "<ellipse fill=\"#8cd499\" stroke=\"black\" stroke-width=\"0\" cx=\"96\" cy=\"-18\" rx=\"50.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"96\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Int (84856)</text>\n",
       "</g>\n",
       "<!-- N84855&#45;&gt;N84856 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>N84855&#45;&gt;N84856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"5,2\" d=\"M96,-101.79C96,-85.13 96,-63.46 96,-46.47\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.5,-46.08 96,-36.08 92.5,-46.08 99.5,-46.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-72.8\" font-family=\"Times,serif\" font-size=\"14.00\">RETURN</text>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">execution_count</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x713d95cb3250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where are our tasks? :anguished:\n",
    "\n",
    "It is important to note here that AiiDA does not store the plain Python function we used to define our tasks in its\n",
    "database. Remember, the AiiDA classes derived from `Node` implement this functionality, so AiiDA doesn't know how to\n",
    "store the data in the database.  Thankfully, we can easily resolve this issue by adding the `@task.calcfunction`\n",
    "decorator to our `sleep_and_print` function. We now assume that we are dealing with AiiDA `ORM` data types inside the\n",
    "task, so we access their actual `value`s inside the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c9e9e848b64d4d8a7c8b379c03ddeb",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'Provena…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  lets_start\n",
      "update task state:  lets_continue\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|run_tasks]: Run task: lets_start, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|run_tasks]: Run task: lets_start, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\n",
      "update task state:  lets_start\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|update_task_state]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|update_task_state]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's continue\n",
      "update task state:  lets_continue\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|update_task_state]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|update_task_state]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  lets_start FINISHED\n",
      "task:  lets_continue FINISHED\n",
      "is workgraph finished:  True\n",
      "workgraph outputs:  []\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84857|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84857|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize workgraph Provenance restored\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'new_data': {},\n",
       " 'execution_count': <Int: uuid: f30a490f-1733-4ce9-8c14-b396368dd9dc (pk: 84864) value: 0>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@task.calcfunction\n",
    "def sleep_and_print(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    print(print_statement.value)\n",
    "\n",
    "wg = WorkGraph(\"Provenance restored\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_continue\", sleep_time=1, print_statement=\"Let's continue\"\n",
    ")\n",
    "\n",
    "task2.waiting_on.add('lets_start')\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"452pt\" height=\"180pt\"\n",
       " viewBox=\"0.00 0.00 451.50 180.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 176)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-176 447.5,-176 447.5,4 -4,4\"/>\n",
       "<!-- N84857 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>N84857</title>\n",
       "<polygon fill=\"#e38851\" stroke=\"red\" stroke-width=\"6\" points=\"368.5,-172 114.5,-172 114.5,-119 368.5,-119 368.5,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">WorkGraph&lt;Provenance restored&gt; (84857)</text>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">State: finished</text>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Exit Code: 0</text>\n",
       "</g>\n",
       "<!-- N84860 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>N84860</title>\n",
       "<polygon fill=\"#de707f\" fill-opacity=\"0.466667\" stroke=\"black\" stroke-width=\"0\" points=\"149,-53 0,-53 0,0 149,0 149,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"74.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">sleep_and_print (84860)</text>\n",
       "<text text-anchor=\"middle\" x=\"74.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">State: finished</text>\n",
       "<text text-anchor=\"middle\" x=\"74.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Exit Code: 0</text>\n",
       "</g>\n",
       "<!-- N84857&#45;&gt;N84860 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>N84857&#45;&gt;N84860</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M188.16,-118.93C178.06,-113.43 167.76,-107.35 158.5,-101 140.8,-88.87 122.71,-73.49 107.86,-59.93\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.13,-57.27 100.41,-53.04 105.37,-62.4 110.13,-57.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-89.8\" font-family=\"Times,serif\" font-size=\"14.00\">CALL_CALC</text>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">lets_start</text>\n",
       "</g>\n",
       "<!-- N84863 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>N84863</title>\n",
       "<polygon fill=\"#de707f\" fill-opacity=\"0.466667\" stroke=\"black\" stroke-width=\"0\" points=\"316,-53 167,-53 167,0 316,0 316,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">sleep_and_print (84863)</text>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">State: finished</text>\n",
       "<text text-anchor=\"middle\" x=\"241.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Exit Code: 0</text>\n",
       "</g>\n",
       "<!-- N84857&#45;&gt;N84863 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>N84857&#45;&gt;N84863</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M241.5,-118.82C241.5,-102.52 241.5,-81.18 241.5,-63.23\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245,-63.12 241.5,-53.12 238,-63.12 245,-63.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-89.8\" font-family=\"Times,serif\" font-size=\"14.00\">CALL_CALC</text>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">lets_continue</text>\n",
       "</g>\n",
       "<!-- N84864 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>N84864</title>\n",
       "<ellipse fill=\"#8cd499\" stroke=\"black\" stroke-width=\"0\" cx=\"384.5\" cy=\"-26.5\" rx=\"50.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"384.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Int (84864)</text>\n",
       "</g>\n",
       "<!-- N84857&#45;&gt;N84864 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>N84857&#45;&gt;N84864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"5,2\" d=\"M297.92,-118.91C307.21,-113.59 316.43,-107.58 324.5,-101 341.36,-87.24 356.79,-68.12 367.78,-52.82\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"370.86,-54.53 373.72,-44.33 365.12,-50.52 370.86,-54.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"398.5\" y=\"-89.8\" font-family=\"Times,serif\" font-size=\"14.00\">RETURN</text>\n",
       "<text text-anchor=\"middle\" x=\"398.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">execution_count</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x713d9509bb80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On creating, returning, and linking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we would like to specify data dependencies, we should define a `task.calcfunction` that actually\n",
    "returns some output so that we can then link it as an input to another task (before, we were only printing).\n",
    "\n",
    "The function in the next cell achieves just that. Here, we have manually specified our `outputs` in the decorator, and\n",
    "we return a clone of the `print_statement`, as returning the actual data node would create a cycle in the graph, which\n",
    "is forbidden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b764ed95478c4a928e7ce4d9ed060cb1",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'Linked …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "update task state:  actual_print_task\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84895|WorkGraphEngine|on_except]: Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 88, in _get_node_by_link_label\n",
      "    node = attribute_dict[label]\n",
      "KeyError: 'keys'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 133, in __getattr__\n",
      "    return self._get_node_by_link_label(label=name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 116, in _get_node_by_link_label\n",
      "    raise NotExistent from exception\n",
      "aiida.common.exceptions.NotExistent\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py\", line 228, in execute\n",
      "    result = self.run_fn(*self.args, **self.kwargs)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 288, in run\n",
      "    return self._do_step()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 303, in _do_step\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1018, in run_tasks\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 964, in run_tasks\n",
      "    args, kwargs, var_args, var_kwargs, args_dict = self.get_inputs(name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1248, in get_inputs\n",
      "    inputs[input[\"name\"]] = get_nested_dict(\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py\", line 73, in get_nested_dict\n",
      "    f\"{name} not exist in the dictionary. Available keys: {current.keys()}\"\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 139, in __getattr__\n",
      "    raise NotExistentAttributeError(\n",
      "aiida.common.exceptions.NotExistentAttributeError: Node<84898> does not have an output with link label 'keys'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84895|WorkGraphEngine|on_except]: Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 88, in _get_node_by_link_label\n",
      "    node = attribute_dict[label]\n",
      "KeyError: 'keys'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 133, in __getattr__\n",
      "    return self._get_node_by_link_label(label=name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 116, in _get_node_by_link_label\n",
      "    raise NotExistent from exception\n",
      "aiida.common.exceptions.NotExistent\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py\", line 228, in execute\n",
      "    result = self.run_fn(*self.args, **self.kwargs)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 288, in run\n",
      "    return self._do_step()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 303, in _do_step\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1018, in run_tasks\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 964, in run_tasks\n",
      "    args, kwargs, var_args, var_kwargs, args_dict = self.get_inputs(name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1248, in get_inputs\n",
      "    inputs[input[\"name\"]] = get_nested_dict(\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py\", line 73, in get_nested_dict\n",
      "    f\"{name} not exist in the dictionary. Available keys: {current.keys()}\"\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 139, in __getattr__\n",
      "    raise NotExistentAttributeError(\n",
      "aiida.common.exceptions.NotExistentAttributeError: Node<84898> does not have an output with link label 'keys'\n",
      "\n"
     ]
    },
    {
     "ename": "NotExistentAttributeError",
     "evalue": "Node<84898> does not have an output with link label 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:88\u001b[0m, in \u001b[0;36mNodeLinksManager._get_node_by_link_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[43mattribute_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Check whether the label contains a double underscore, in which case we want to warn the user that this is\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# deprecated. However, we need to exclude labels that corresponds to dunder methods, i.e., those that start\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# and end with a double underscore.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'keys'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotExistent\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:133\u001b[0m, in \u001b[0;36mNodeLinksManager.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_by_link_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotExistent \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Note: in order for TAB-completion to work, we need to raise an exception that also inherits from\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# `AttributeError`, so that `getattr(node.inputs, 'some_label', some_default)` returns `some_default`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Otherwise, the exception is not caught by `getattr` and is propagated, instead of returning the default.\u001b[39;00m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:116\u001b[0m, in \u001b[0;36mNodeLinksManager._get_node_by_link_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NotExistent \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotExistent \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[0;31mNotExistent\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m task5 \u001b[38;5;241m=\u001b[39m wg\u001b[38;5;241m.\u001b[39madd_task(\n\u001b[1;32m     18\u001b[0m     sleep_and_print, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_print_task\u001b[39m\u001b[38;5;124m\"\u001b[39m, sleep_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, print_statement\u001b[38;5;241m=\u001b[39mreturn_task\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mreturn_statement\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m display(wg)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mwg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/workgraph.py:107\u001b[0m, in \u001b[0;36mWorkGraph.run\u001b[0;34m(self, inputs, metadata)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs(metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[0;32m--> 107\u001b[0m result, node \u001b[38;5;241m=\u001b[39m \u001b[43maiida\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWorkGraphEngine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m node\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/launch.py:65\u001b[0m, in \u001b[0;36mrun_get_node\u001b[0;34m(process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     runner \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mget_manager()\u001b[38;5;241m.\u001b[39mget_runner()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/runners.py:291\u001b[0m, in \u001b[0;36mRunner.run_get_node\u001b[0;34m(self, process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_get_node\u001b[39m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m, process: TYPE_RUN_PROCESS, inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultAndNode:\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the process with the supplied inputs in this runner that will block until the process is completed.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    The return value will be the results of the completed process\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    :return: tuple of the outputs of the process and the calculation node\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     result, node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ResultAndNode(result, node)\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/runners.py:261\u001b[0m, in \u001b[0;36mRunner._run\u001b[0;34m(self, process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, kill_process)\n\u001b[1;32m    260\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGTERM, kill_process)\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mprocess_inited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, original_handler_int)\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/processes.py:90\u001b[0m, in \u001b[0;36mensure_not_closed.<locals>.func_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mClosedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcess is closed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/processes.py:1203\u001b[0m, in \u001b[0;36mProcess.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_terminated():\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_until_terminated())\n\u001b[0;32m-> 1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py:228\u001b[0m, in \u001b[0;36mRunning.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:288\u001b[0m, in \u001b[0;36mWorkGraphEngine.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup()\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:303\u001b[0m, in \u001b[0;36mWorkGraphEngine._do_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m result: t\u001b[38;5;241m.\u001b[39mAny \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinue_workgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _PropagateReturn \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    305\u001b[0m     finished, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, exception\u001b[38;5;241m.\u001b[39mexit_code\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:644\u001b[0m, in \u001b[0;36mWorkGraphEngine.continue_workgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks ready to run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(task_to_run)))\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_to_run\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:1018\u001b[0m, in \u001b[0;36mWorkGraphEngine.run_tasks\u001b[0;34m(self, names, continue_workgraph)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# exclude the current tasks from the next run\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_workgraph:\n\u001b[0;32m-> 1018\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinue_workgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALCJOB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWORKCHAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# process = run_get_node(executor, *args, **kwargs)\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:644\u001b[0m, in \u001b[0;36mWorkGraphEngine.continue_workgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks ready to run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(task_to_run)))\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_to_run\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:964\u001b[0m, in \u001b[0;36mWorkGraphEngine.run_tasks\u001b[0;34m(self, names, continue_workgraph)\u001b[0m\n\u001b[1;32m    962\u001b[0m executor, _ \u001b[38;5;241m=\u001b[39m get_executor(task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    963\u001b[0m \u001b[38;5;66;03m# print(\"executor: \", executor)\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m args, kwargs, var_args, var_kwargs, args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_tasks[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    966\u001b[0m     kwargs[key] \u001b[38;5;241m=\u001b[39m args[i]\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:1248\u001b[0m, in \u001b[0;36mWorkGraphEngine.get_inputs\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             inputs[\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_tasks[link[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_node\u001b[39m\u001b[38;5;124m\"\u001b[39m]][\n\u001b[1;32m   1245\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1246\u001b[0m             ]\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1248\u001b[0m             inputs[\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mget_nested_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tasks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom_node\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom_socket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;66;03m# handle the case of multiple outputs\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py:73\u001b[0m, in \u001b[0;36mget_nested_dict\u001b[0;34m(d, name, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m---> 73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not exist in the dictionary. Available keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m     current \u001b[38;5;241m=\u001b[39m current[key]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m current\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:139\u001b[0m, in \u001b[0;36mNodeLinksManager.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotExistent \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Note: in order for TAB-completion to work, we need to raise an exception that also inherits from\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# `AttributeError`, so that `getattr(node.inputs, 'some_label', some_default)` returns `some_default`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Otherwise, the exception is not caught by `getattr` and is propagated, instead of returning the default.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_incoming \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotExistentAttributeError(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode<\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mpk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m> does not have an \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with link label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m: Node<84898> does not have an output with link label 'keys'"
     ]
    }
   ],
   "source": [
    "@task.calcfunction(\n",
    "    outputs=[\n",
    "        {'name': 'return_statement', 'identifier': 'workgraph.Any'}\n",
    "    ]\n",
    ")\n",
    "def sleep_and_return(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    # Returning the input directly would create a cycle in the graph\n",
    "    return print_statement.clone()\n",
    "\n",
    "wg = WorkGraph(\"Linked data\")\n",
    "\n",
    "return_task = wg.add_task(\n",
    "    sleep_and_return, name=\"return_task\", sleep_time=1, print_statement=\"I will print the previous return.\"\n",
    ")\n",
    "\n",
    "task5 = wg.add_task(\n",
    "    sleep_and_print, name=\"actual_print_task\", sleep_time=1, print_statement=return_task.outputs.return_statement\n",
    ")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "update task state:  actual_print_task\n",
      "update task state:  lets_start\n",
      "update task state:  lets_continue\n",
      "update task state:  wait_both\n",
      "update task state:  disconnected_task\n",
      "update task state:  intermediate_step\n",
      "update task state:  final_step\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task,lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task,lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task,lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task,lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84890|WorkGraphEngine|on_except]: Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 88, in _get_node_by_link_label\n",
      "    node = attribute_dict[label]\n",
      "KeyError: 'keys'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 133, in __getattr__\n",
      "    return self._get_node_by_link_label(label=name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 116, in _get_node_by_link_label\n",
      "    raise NotExistent from exception\n",
      "aiida.common.exceptions.NotExistent\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py\", line 228, in execute\n",
      "    result = self.run_fn(*self.args, **self.kwargs)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 288, in run\n",
      "    return self._do_step()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 303, in _do_step\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1018, in run_tasks\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 964, in run_tasks\n",
      "    args, kwargs, var_args, var_kwargs, args_dict = self.get_inputs(name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1248, in get_inputs\n",
      "    inputs[input[\"name\"]] = get_nested_dict(\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py\", line 73, in get_nested_dict\n",
      "    f\"{name} not exist in the dictionary. Available keys: {current.keys()}\"\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 139, in __getattr__\n",
      "    raise NotExistentAttributeError(\n",
      "aiida.common.exceptions.NotExistentAttributeError: Node<84893> does not have an output with link label 'keys'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84890|WorkGraphEngine|on_except]: Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 88, in _get_node_by_link_label\n",
      "    node = attribute_dict[label]\n",
      "KeyError: 'keys'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 133, in __getattr__\n",
      "    return self._get_node_by_link_label(label=name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 116, in _get_node_by_link_label\n",
      "    raise NotExistent from exception\n",
      "aiida.common.exceptions.NotExistent\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py\", line 228, in execute\n",
      "    result = self.run_fn(*self.args, **self.kwargs)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 288, in run\n",
      "    return self._do_step()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 303, in _do_step\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1018, in run_tasks\n",
      "    self.continue_workgraph()\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 644, in continue_workgraph\n",
      "    self.run_tasks(task_to_run)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 964, in run_tasks\n",
      "    args, kwargs, var_args, var_kwargs, args_dict = self.get_inputs(name)\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py\", line 1248, in get_inputs\n",
      "    inputs[input[\"name\"]] = get_nested_dict(\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py\", line 73, in get_nested_dict\n",
      "    f\"{name} not exist in the dictionary. Available keys: {current.keys()}\"\n",
      "  File \"/home/geiger_j/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py\", line 139, in __getattr__\n",
      "    raise NotExistentAttributeError(\n",
      "aiida.common.exceptions.NotExistentAttributeError: Node<84893> does not have an output with link label 'keys'\n",
      "\n"
     ]
    },
    {
     "ename": "NotExistentAttributeError",
     "evalue": "Node<84893> does not have an output with link label 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:88\u001b[0m, in \u001b[0;36mNodeLinksManager._get_node_by_link_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[43mattribute_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Check whether the label contains a double underscore, in which case we want to warn the user that this is\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# deprecated. However, we need to exclude labels that corresponds to dunder methods, i.e., those that start\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# and end with a double underscore.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'keys'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotExistent\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:133\u001b[0m, in \u001b[0;36mNodeLinksManager.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_by_link_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotExistent \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Note: in order for TAB-completion to work, we need to raise an exception that also inherits from\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# `AttributeError`, so that `getattr(node.inputs, 'some_label', some_default)` returns `some_default`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Otherwise, the exception is not caught by `getattr` and is propagated, instead of returning the default.\u001b[39;00m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:116\u001b[0m, in \u001b[0;36mNodeLinksManager._get_node_by_link_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NotExistent \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotExistent \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[0;31mNotExistent\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 34\u001b[0m\n\u001b[1;32m     29\u001b[0m task5 \u001b[38;5;241m=\u001b[39m wg\u001b[38;5;241m.\u001b[39madd_task(\n\u001b[1;32m     30\u001b[0m     sleep_and_print, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, sleep_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, print_statement\u001b[38;5;241m=\u001b[39mtask4\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_statement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m wg\n\u001b[0;32m---> 34\u001b[0m \u001b[43mwg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/workgraph.py:107\u001b[0m, in \u001b[0;36mWorkGraph.run\u001b[0;34m(self, inputs, metadata)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs(metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[0;32m--> 107\u001b[0m result, node \u001b[38;5;241m=\u001b[39m \u001b[43maiida\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWorkGraphEngine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m node\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/launch.py:65\u001b[0m, in \u001b[0;36mrun_get_node\u001b[0;34m(process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     runner \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mget_manager()\u001b[38;5;241m.\u001b[39mget_runner()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/runners.py:291\u001b[0m, in \u001b[0;36mRunner.run_get_node\u001b[0;34m(self, process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_get_node\u001b[39m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m, process: TYPE_RUN_PROCESS, inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultAndNode:\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the process with the supplied inputs in this runner that will block until the process is completed.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    The return value will be the results of the completed process\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    :return: tuple of the outputs of the process and the calculation node\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     result, node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ResultAndNode(result, node)\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/engine/runners.py:261\u001b[0m, in \u001b[0;36mRunner._run\u001b[0;34m(self, process, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, kill_process)\n\u001b[1;32m    260\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGTERM, kill_process)\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mprocess_inited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, original_handler_int)\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/processes.py:90\u001b[0m, in \u001b[0;36mensure_not_closed.<locals>.func_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mClosedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcess is closed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/processes.py:1203\u001b[0m, in \u001b[0;36mProcess.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_terminated():\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_until_terminated())\n\u001b[0;32m-> 1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/plumpy/process_states.py:228\u001b[0m, in \u001b[0;36mRunning.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:288\u001b[0m, in \u001b[0;36mWorkGraphEngine.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup()\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:303\u001b[0m, in \u001b[0;36mWorkGraphEngine._do_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m result: t\u001b[38;5;241m.\u001b[39mAny \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinue_workgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _PropagateReturn \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    305\u001b[0m     finished, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, exception\u001b[38;5;241m.\u001b[39mexit_code\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:644\u001b[0m, in \u001b[0;36mWorkGraphEngine.continue_workgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks ready to run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(task_to_run)))\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_to_run\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:1018\u001b[0m, in \u001b[0;36mWorkGraphEngine.run_tasks\u001b[0;34m(self, names, continue_workgraph)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# exclude the current tasks from the next run\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_workgraph:\n\u001b[0;32m-> 1018\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinue_workgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALCJOB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWORKCHAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# process = run_get_node(executor, *args, **kwargs)\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:644\u001b[0m, in \u001b[0;36mWorkGraphEngine.continue_workgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks ready to run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(task_to_run)))\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_to_run\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:964\u001b[0m, in \u001b[0;36mWorkGraphEngine.run_tasks\u001b[0;34m(self, names, continue_workgraph)\u001b[0m\n\u001b[1;32m    962\u001b[0m executor, _ \u001b[38;5;241m=\u001b[39m get_executor(task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    963\u001b[0m \u001b[38;5;66;03m# print(\"executor: \", executor)\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m args, kwargs, var_args, var_kwargs, args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_tasks[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    966\u001b[0m     kwargs[key] \u001b[38;5;241m=\u001b[39m args[i]\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/engine/workgraph.py:1248\u001b[0m, in \u001b[0;36mWorkGraphEngine.get_inputs\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             inputs[\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_tasks[link[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_node\u001b[39m\u001b[38;5;124m\"\u001b[39m]][\n\u001b[1;32m   1245\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1246\u001b[0m             ]\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1248\u001b[0m             inputs[\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mget_nested_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tasks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom_node\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom_socket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;66;03m# handle the case of multiple outputs\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida_workgraph/utils/__init__.py:73\u001b[0m, in \u001b[0;36mget_nested_dict\u001b[0;34m(d, name, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m---> 73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not exist in the dictionary. Available keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m     current \u001b[38;5;241m=\u001b[39m current[key]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m current\n",
      "File \u001b[0;32m~/.aiida_venvs/fair-workflows-workshop/lib/python3.10/site-packages/aiida/orm/utils/managers.py:139\u001b[0m, in \u001b[0;36mNodeLinksManager.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotExistent \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Note: in order for TAB-completion to work, we need to raise an exception that also inherits from\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# `AttributeError`, so that `getattr(node.inputs, 'some_label', some_default)` returns `some_default`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Otherwise, the exception is not caught by `getattr` and is propagated, instead of returning the default.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_incoming \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotExistentAttributeError(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode<\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mpk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m> does not have an \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with link label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m: Node<84893> does not have an output with link label 'keys'"
     ]
    }
   ],
   "source": [
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_continue\", sleep_time=1, print_statement=\"Let's continue\"\n",
    ")\n",
    "\n",
    "task2.waiting_on.add('lets_start')\n",
    "\n",
    "task3 = wg.add_task(\n",
    "    sleep_and_print, name=\"wait_both\", sleep_time=1, print_statement=\"I need to wait for both\"\n",
    ")\n",
    "\n",
    "task3.waiting_on.add('lets_start')\n",
    "task3.waiting_on.add('lets_continue')\n",
    "\n",
    "disconnected_task = wg.add_task(\n",
    "    sleep_and_print, name=\"disconnected_task\", sleep_time=10, print_statement=\"I have no dependencies, but I am one.\"\n",
    ")\n",
    "\n",
    "task4 = wg.add_task(\n",
    "    sleep_and_return, name=\"intermediate_step\", sleep_time=1, print_statement=\"I will print the previous return.\"\n",
    ")\n",
    "\n",
    "task4.waiting_on.add('disconnected_task')\n",
    "task4.waiting_on.add('wait_both')\n",
    "\n",
    "task5 = wg.add_task(\n",
    "    sleep_and_print, name=\"final_step\", sleep_time=1, print_statement=task4.outputs['return_statement']\n",
    ")\n",
    "\n",
    "wg\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"query_and_diag\")\n",
    "\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_code,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "\n",
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_code,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This how you retrieve your outputs after a run with WorkGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "diag_task.node.outputs['aiida_shell_5_eigvals_txt']\n",
    "diag_task.node.outputs.eigvals.get_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending WorkGraph with arbitrary python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"compute_eigvals_wg\")\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_task,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "\n",
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    global diag_output_filename\n",
    "    arr = np.loadtxt(dirpath / diag_output_filename)\n",
    "    return {\"eigvals\": orm.ArrayData(arr)}\n",
    "\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_task,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "\n",
    "# Why do you have to wrap your function? So aiida understands your function\n",
    "# Try comment out the code and look at the provenance graph\n",
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "    return orm.Float(np.mean(eigenvalues.get_array()))\n",
    "\n",
    "\n",
    "# plot_task = wg.add_task(\n",
    "#     plot, name=\"plot_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    "# )\n",
    "mean_task = wg.add_task(\n",
    "    compute_mean, name=\"mean_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    ")\n",
    "\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the `compute_mean` result (the orm.Float) is not present in the provenance graph when we remove the calcfunction decorator because it is not stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph.utils import generate_node_graph\n",
    "generate_node_graph(wg.pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can display the image in a similar way by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(wg.tasks[\"plot_task\"].outputs[\"result\"].value)  # SinglefileData\n",
    "with wg.tasks[\"plot_task\"].outputs[\"result\"].value.as_path() as filepath:\n",
    "    display(Image(filename=(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_parser(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])  # this is small aiida detail\n",
    "    data = orm.ArrayData(arr)\n",
    "    data.attributes[\"length\"] = len(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "\n",
    "@task.graph_builder(\n",
    "    outputs=[\n",
    "        {\"name\": \"eigvals\", \"from\": \"diag_task.eigvals\"},\n",
    "        {\"name\": \"mean_eigval\", \"from\": \"compute_mean.result\"},\n",
    "    ]\n",
    ")\n",
    "def query_and_diag(matrix_pk: orm.Int):\n",
    "    wg = WorkGraph()\n",
    "    query_output_filename = f\"matrix-{matrix_pk.value}.npy\"\n",
    "\n",
    "    query_code = orm.load_code(f\"query@localhost\")\n",
    "    query_task = wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"query_task\",\n",
    "        command=query_code,\n",
    "        arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "        nodes={\n",
    "            \"db_path\": \"/Users/alexgo/code/fair-workflows-workshop/data/euro-scipy-2024/diag-wf/remote/matrices.db\",\n",
    "            \"matrix_pk\": matrix_pk,\n",
    "        },\n",
    "        outputs=[query_output_filename],\n",
    "    )\n",
    "    query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "    diag_output_filename = f\"matrix-{matrix_pk.value}-eigvals.txt\"\n",
    "\n",
    "    diag_code = orm.load_code(f\"diag@localhost\")\n",
    "    wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"diag_task\",\n",
    "        command=diag_code,\n",
    "        arguments=[\"{matrix_file}\"],\n",
    "        parser=array_parser,\n",
    "        nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "        outputs=[diag_output_filename],\n",
    "        parser_outputs=[{\"name\": \"eigvals\"}],\n",
    "    )\n",
    "\n",
    "    @task.calcfunction\n",
    "    def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "        node = orm.Float(np.mean(eigenvalues.get_array()))\n",
    "        node.attributes[\"length\"] = len(eigenvalues)\n",
    "        return node\n",
    "\n",
    "    # TODO add compute_mean\n",
    "\n",
    "    return wg\n",
    "\n",
    "\n",
    "wg = WorkGraph()\n",
    "wg.add_task(query_and_diag)\n",
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "for i in range(1, 5):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to collect all the results and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO you don't have to compute anymore the mean value because it is exposed by the graph_builder\n",
    "@task.calcfunction\n",
    "def assemble_plot(**collected_eigvals) -> dict[str, orm.Data]:\n",
    "    # return orm.List([arr.get_array() for arr in x.values()])\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    label: str\n",
    "    eigval_data: orm.ArrayData\n",
    "    mean_eigenvalues = []\n",
    "    for _, eigval_data in collected_eigvals.items():\n",
    "        mean_eigenvalues.append(np.mean(eigval_data.get_array()))\n",
    "    ax.hist(mean_eigenvalues, bins=10, color=\"c\", edgecolor=\"black\")\n",
    "    ax.set_title(\"Histogram of Eigenvalues\")\n",
    "    ax.set_xlabel(\"Eigenvalue\")\n",
    "    filename = \"plot.jpg\"\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    return orm.SinglefileData(Path(filename).absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "assemble_plot_task = wg.add_task(assemble_plot, name=\"assemble_plot_task\")\n",
    "# we have to increase the link limit because by default workgraph only supports one link per input socket\n",
    "assemble_plot_task.inputs[\"collected_eigvals\"].link_limit = 50\n",
    "for i in range(1, 10):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "    wg.add_link(\n",
    "        query_and_diag_task.outputs[\"eigvals\"],\n",
    "        assemble_plot_task.inputs[\"collected_eigvals\"],\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QueryBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can query now from our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also introduce filters in our queriesS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    filters={\n",
    "        'attributes.length': {'==': 50}\n",
    "    },\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we create if conditions workflows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def compute_mean(eigvals: orm.ArrayData) -> orm.Float:\n",
    "    return orm.Float(np.mean(eigvals.get_array()))\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def eigvals_less(mean_eigval: orm.Float) -> bool:\n",
    "    return mean_eigval < 14.5\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def heureka(eigvals, pk):\n",
    "    try:\n",
    "        path = Path(\"storage\").absolute()\n",
    "        path.mkdir(exist_ok=True)\n",
    "        result_path = path / f\"eigvals-pk{pk}.npy\"\n",
    "        np.save(result_path, eigvals.get_array())\n",
    "        success = orm.Int(0)\n",
    "        success.attributes[\"path\"] = str(result_path)\n",
    "        success.attributes[\"error\"] = \"\"\n",
    "    except Exception as err:\n",
    "        success = orm.Int(1)\n",
    "        success.attributes[\"path\"] = \"\"\n",
    "        success.attributes[\"error\"] = str(err)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"someother\")\n",
    "\n",
    "martix_pk = 5\n",
    "\n",
    "query_and_diag_task = wg.add_task(\n",
    "    query_and_diag, name=f\"query_and_diag_pk{matrix_pk}\", matrix_pk=orm.Int(matrix_pk)\n",
    ")\n",
    "compute_mean_task = wg.add_task(\n",
    "    compute_mean,\n",
    "    name=f\"compute_mean_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    ")\n",
    "eigvals_less_task = wg.add_task(\n",
    "    eigvals_less,\n",
    "    name=f\"eigvals_less_task_pk{matrix_pk}\",\n",
    "    mean_eigval=compute_mean_task.outputs[\"result\"],\n",
    ")\n",
    "if_less = wg.add_task(\n",
    "    \"If\", name=f\"if_less_pk{matrix_pk}\", conditions=eigvals_less_task.outputs[\"result\"]\n",
    ")  # there as specific conditions socket\n",
    "heureka_task = wg.add_task(\n",
    "    heureka,\n",
    "    name=f\"heureka_task_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    "    pk=orm.Int(i),\n",
    ")\n",
    "if_less.children.add(f\"heureka_task_pk{matrix_pk}\")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
