{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create more complex workflows\n",
    "\n",
    "## Concatenating several scripts to one workflow and more :)\n",
    "\n",
    "In the previous notebook, we have seen how we can run arbitrary executables through `aiida-shell` without requiring any\n",
    "code-specific infrastructure (typically contained in a dedicated AiiDA plugin). In addition, we have seen how we can\n",
    "feed the output of one task to the input of another task, linking the two and effectively creating a workflow.\n",
    "\n",
    "Building on this concept, the `aiida-workgraph` provides the capability to create workflows in the same manner as one would\n",
    "build up an actual graph. That is, by adding nodes and edges to it. It further extends the possible building blocks from\n",
    "external scripts to existing AiiDA buliding blocks (`CalcFunction`s, `CalcJob`s, `WorkChain`s, etc.), as well as custom\n",
    "Python code.\n",
    "\n",
    "We'll cover lots of material in this notebook, so strap yourself in and buckle up! :rocket:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the AiiDA jupyter notebook extension, check the profile status, import the libraries all that we need. So nothing new\n",
    "here, really..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from aiida import orm\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph\n",
    "\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.utils import generate_node_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_code = orm.load_code('diagonalization@localhost')  # The computer label can also be omitted here\n",
    "query_code = orm.load_code('remote_query@localhost')  # The computer label can also be omitted here\n",
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkGraph vs. provenance graph\n",
    "\n",
    "As evident from the import statement:\n",
    "\n",
    "```python\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "```\n",
    "\n",
    "the first entity we'll be using is, of course, the `WorkGraph`. In addition, we import the `task`, which actually\n",
    "presents the `WorkGraph` equivalent of a *node* in the graphs we'll be building up.\n",
    "\n",
    "In line with common graph nomenclature, we'd have loved to use the **Node** keyword for that, but remember, the `Node`\n",
    "class is already defined in `aiida-core`. To avoid confusion, it is good to mention here, that we will now be talking\n",
    "about two different kinds of graphs:\n",
    "- **The provenance graph**: AiiDA's way of storing the **Data** and **Processes** inside the SQL database as **Node**s\n",
    "  and **Link**\n",
    "- **The WorkGraph**: The workflow we are building up using the `aiida-workgraph` library\n",
    "\n",
    "As such, we can build up our workflow as a **WorkGraph**, run it, and AiiDA will store all data in its database, allowing\n",
    "us to explore the resulting **provenance graph** of our workflow.\n",
    "\n",
    "Let's maybe best start with some simple examples, this will make things clear. We'll close the cycle to the previous\n",
    "notebook in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_and_print(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time)\n",
    "    print(print_statement)\n",
    "\n",
    "wg = WorkGraph('First WG')\n",
    "\n",
    "wg.add_task(sleep_and_print)\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you just created your first `WorkGraph`! Let's unpack the code: We first created a very simple Python\n",
    "function, we then instantiated the `WorkGraph`, and added our function as a task (remember, think of *graph nodes*).\n",
    "\n",
    "`aiida-workgraph` comes with a visualization tool in which we can see the setup of our workflow. Note that we didn't\n",
    "actually run it at this point, yet. Let's add a second task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.add_task(sleep_and_print)\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we now have two disconnected tasks in our workgraph. To define dependencies between those, we can either\n",
    "link inputs and outpus, just as we did before with `aiida-shell`, or explicitly enforce that the second task has to wait\n",
    "on the first one. For now, let's actually focus on the second case (the first one will require us to introduce a few\n",
    "more concepts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.tasks.sleep_and_print2.waiting_on.add('sleep_and_print1')\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we accessed the second task through our `WorkGraph` instance, `wg`. However, the `add_task` function\n",
    "actually returns the task, so we can also write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph('First WG')\n",
    "\n",
    "task1 = wg.add_task(sleep_and_print)\n",
    "task2 = wg.add_task(sleep_and_print)\n",
    "\n",
    "task2.waiting_on.add('sleep_and_print1')\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which achieves the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Python code with WorkGraph and AiiDA provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we want to actually run our workflow, we should specify some inputs to our tasks. We can do that, as well as name our\n",
    "tasks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"Run WG\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_continue\", sleep_time=1, print_statement=\"Let's continue\"\n",
    ")\n",
    "\n",
    "task2.waiting_on.add('lets_start')\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like everything worked out smoothly. Now, let's show the provenance graph of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where are our tasks? :anguished:\n",
    "\n",
    "It is important to note here that AiiDA does not store the plain Python function we used to define our tasks in its\n",
    "database. Remember, the AiiDA classes derived from `Node` implement this functionality, so AiiDA doesn't know how to\n",
    "store the data in the database.  Thankfully, we can easily resolve this issue by adding the `@task.calcfunction`\n",
    "decorator to our `sleep_and_print` function. We now assume that we are dealing with AiiDA `ORM` data types inside the\n",
    "task, so we access their actual `value`s inside the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def sleep_and_print(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    print(print_statement.value)\n",
    "\n",
    "wg = WorkGraph(\"Provenance restored\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_continue\", sleep_time=1, print_statement=\"Let's continue\"\n",
    ")\n",
    "\n",
    "task2.waiting_on.add('lets_start')\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On creating, returning, and linking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we would like to specify data dependencies, we should define a `task.calcfunction` that actually\n",
    "returns some output so that we can then link it as an input to another task (before, we were only printing).\n",
    "\n",
    "The function in the next cell achieves just that. Here, we have manually specified our `outputs` in the decorator, and\n",
    "we return a clone of the `print_statement`, as returning the actual data node would create a cycle in the graph, which\n",
    "is forbidden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721ad9441cc24f80abcf163fa82e923c",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'Linked …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "update task state:  actual_print_task\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: return_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|run_tasks]: Run task: return_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  return_task\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|update_task_state]: Task: return_task finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: actual_print_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|run_tasks]: Run task: actual_print_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will print the previous return.\n",
      "update task state:  actual_print_task\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|update_task_state]: Task: actual_print_task finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|update_task_state]: Task: actual_print_task finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  return_task FINISHED\n",
      "task:  actual_print_task FINISHED\n",
      "is workgraph finished:  True\n",
      "workgraph outputs:  []\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84916|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84916|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize workgraph Linked data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'new_data': {},\n",
       " 'execution_count': <Int: uuid: 6e9f08e5-28d8-4ad6-a259-f79518a2f3df (pk: 84923) value: 0>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@task.calcfunction(\n",
    "    outputs=[\n",
    "        {'name': 'return_statement'}\n",
    "    ]\n",
    ")\n",
    "def sleep_and_return(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    # Returning the input directly would create a cycle in the graph\n",
    "    return {'return_statement': print_statement.clone()}\n",
    "\n",
    "wg = WorkGraph(\"Linked data\")\n",
    "\n",
    "return_task = wg.add_task(\n",
    "    sleep_and_return, name=\"return_task\", sleep_time=1, print_statement=\"I will print the previous return.\"\n",
    ")\n",
    "\n",
    "task5 = wg.add_task(\n",
    "    sleep_and_print, name=\"actual_print_task\", sleep_time=1, print_statement=return_task.outputs['return_statement']\n",
    ")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can now define (almost) arbitrarily complex workflows, as shown below. Feel free to play around with this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30669139514be09856fc6937a99071",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "NodeGraphWidget(settings={'minimap': True}, style={'width': '90%', 'height': '600px'}, value={'name': 'Arbitra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  lets_start\n",
      "update task state:  lets_continue\n",
      "update task state:  wait_both\n",
      "update task state:  disconnected_task\n",
      "update task state:  intermediate_step\n",
      "update task state:  final_step\n",
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_start,disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: lets_start, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: lets_start, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start\n",
      "update task state:  lets_start\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: lets_start finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue,disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: lets_continue,disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: lets_continue, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's continue\n",
      "update task state:  lets_continue\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: lets_continue finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: wait_both,disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: wait_both,disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: wait_both, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: wait_both, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to wait for both\n",
      "update task state:  wait_both\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: wait_both finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: wait_both finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: disconnected_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: disconnected_task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: disconnected_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: disconnected_task, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no dependencies, but I am one.\n",
      "update task state:  disconnected_task\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: disconnected_task finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: disconnected_task finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: intermediate_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: intermediate_step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: intermediate_step, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: intermediate_step, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update task state:  intermediate_step\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: intermediate_step finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: intermediate_step finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: final_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: final_step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|run_tasks]: Run task: final_step, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|run_tasks]: Run task: final_step, type: CALCFUNCTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will print the previous return.\n",
      "update task state:  final_step\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|update_task_state]: Task: final_step finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|update_task_state]: Task: final_step finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue workgraph.\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: Continue workgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|continue_workgraph]: tasks ready to run: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  lets_start FINISHED\n",
      "task:  lets_continue FINISHED\n",
      "task:  wait_both FINISHED\n",
      "task:  disconnected_task FINISHED\n",
      "task:  intermediate_step FINISHED\n",
      "task:  final_step FINISHED\n",
      "is workgraph finished:  True\n",
      "workgraph outputs:  []\n",
      "\u001b[34m\u001b[1mReport\u001b[0m: [84924|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REPORT:aiida.orm.nodes.process.workflow.workchain.WorkChainNode:[84924|WorkGraphEngine|finalize]: Finalize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalize workgraph Arbitrary WorkGraph\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'new_data': {},\n",
       " 'execution_count': <Int: uuid: acb1d6ab-7090-45e7-9afa-3e45202d1eaf (pk: 84943) value: 0>}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg = WorkGraph(\"Arbitrary WorkGraph\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\", sleep_time=1, print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print,\n",
    "    name=\"lets_continue\",\n",
    "    sleep_time=1,\n",
    "    print_statement=\"Let's continue\",\n",
    ")\n",
    "\n",
    "task2.waiting_on.add(\"lets_start\")\n",
    "\n",
    "task3 = wg.add_task(\n",
    "    sleep_and_print,\n",
    "    name=\"wait_both\",\n",
    "    sleep_time=1,\n",
    "    print_statement=\"I need to wait for both\",\n",
    ")\n",
    "\n",
    "task3.waiting_on.add(\"lets_start\")\n",
    "task3.waiting_on.add(\"lets_continue\")\n",
    "\n",
    "disconnected_task = wg.add_task(\n",
    "    sleep_and_print,\n",
    "    name=\"disconnected_task\",\n",
    "    sleep_time=5,\n",
    "    print_statement=\"I have no dependencies, but I am one, and I take my time.\",\n",
    ")\n",
    "\n",
    "task4 = wg.add_task(\n",
    "    sleep_and_return,\n",
    "    name=\"intermediate_step\",\n",
    "    sleep_time=1,\n",
    "    print_statement=\"I will print the previous return.\",\n",
    ")\n",
    "\n",
    "task4.waiting_on.add(\"disconnected_task\")\n",
    "task4.waiting_on.add(\"wait_both\")\n",
    "\n",
    "task5 = wg.add_task(\n",
    "    sleep_and_print,\n",
    "    name=\"final_step\",\n",
    "    sleep_time=1,\n",
    "    print_statement=task4.outputs[\"return_statement\"],\n",
    ")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the circle: Back to the `aiida-shell` example\n",
    "\n",
    "Now that we have seen how we can construct simple workflows and define task dependencies with the `WorkGraph`, let's use\n",
    "it to implement the workflow from the previous notebook. The code snippets in the following cells are rather lengthy,\n",
    "however, the way we execute the external executable is the same as before, just that we now add a `ShellJob` `task` to\n",
    "the `WorkGraph` (passing the same arguments as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"query_and_diag\")\n",
    "\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_code,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "# The file name automatically gets converted into an AiiDA link label by `aiida-shell`\n",
    "# Link labels can only have alphanumericy characters and underscores, so we apply the same cleaning to the filename\n",
    "# To be able to reference it later on\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching a parser\n",
    "\n",
    "Now that we have run the query task as before, the next step is the diagonalization. However, we might not only want to\n",
    "write the eigenvalues to an output file, but also parse them, e.g. so that the resulting array is stored\n",
    "**explicitly** in AiiDA's database (rather than just a reference to the file), and so that we can further operate on it\n",
    "directly in our Python code. To achieve that, we deine a parser function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can now pass to our diagonalization task via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_code,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    # Attach parser here\n",
    "    parser=parse_array,\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now allows us to retrieve the eigenvalue outputs directly from the associated AiiDA `Node` attached to the\n",
    "`WorkGraph` `Task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_task.node.outputs['aiida_shell_5_eigvals_txt']\n",
    "diag_task.node.outputs.eigvals.get_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending WorkGraph with arbitrary python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"compute_eigvals_wg\")\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_task,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "\n",
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    global diag_output_filename\n",
    "    arr = np.loadtxt(dirpath / diag_output_filename)\n",
    "    return {\"eigvals\": orm.ArrayData(arr)}\n",
    "\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_task,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "\n",
    "diag_task_link_label = ShellParser.format_link_label(diag_output_filename)\n",
    "\n",
    "\n",
    "# Why do you have to wrap your function? So aiida understands your function\n",
    "# Try comment out the code and look at the provenance graph\n",
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "    return orm.Float(np.mean(eigenvalues.get_array()))\n",
    "\n",
    "\n",
    "# plot_task = wg.add_task(\n",
    "#     plot, name=\"plot_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    "# )\n",
    "mean_task = wg.add_task(\n",
    "    compute_mean, name=\"mean_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    ")\n",
    "\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the `compute_mean` result (the orm.Float) is not present in the provenance graph when we remove the calcfunction decorator because it is not stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_workgraph.utils import generate_node_graph\n",
    "generate_node_graph(wg.pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can display the image in a similar way by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(wg.tasks[\"plot_task\"].outputs[\"result\"].value)  # SinglefileData\n",
    "with wg.tasks[\"plot_task\"].outputs[\"result\"].value.as_path() as filepath:\n",
    "    display(Image(filename=(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_parser(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])  # this is small aiida detail\n",
    "    data = orm.ArrayData(arr)\n",
    "    data.attributes[\"length\"] = len(arr)\n",
    "    return {\"eigvals\": data}\n",
    "\n",
    "\n",
    "@task.graph_builder(\n",
    "    outputs=[\n",
    "        {\"name\": \"eigvals\", \"from\": \"diag_task.eigvals\"},\n",
    "        {\"name\": \"mean_eigval\", \"from\": \"compute_mean.result\"},\n",
    "    ]\n",
    ")\n",
    "def query_and_diag(matrix_pk: orm.Int):\n",
    "    wg = WorkGraph()\n",
    "    query_output_filename = f\"matrix-{matrix_pk.value}.npy\"\n",
    "\n",
    "    query_code = orm.load_code(f\"query@localhost\")\n",
    "    query_task = wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"query_task\",\n",
    "        command=query_code,\n",
    "        arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "        nodes={\n",
    "            \"db_path\": \"/Users/alexgo/code/fair-workflows-workshop/data/euro-scipy-2024/diag-wf/remote/matrices.db\",\n",
    "            \"matrix_pk\": matrix_pk,\n",
    "        },\n",
    "        outputs=[query_output_filename],\n",
    "    )\n",
    "    query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "    diag_output_filename = f\"matrix-{matrix_pk.value}-eigvals.txt\"\n",
    "\n",
    "    diag_code = orm.load_code(f\"diag@localhost\")\n",
    "    wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"diag_task\",\n",
    "        command=diag_code,\n",
    "        arguments=[\"{matrix_file}\"],\n",
    "        parser=array_parser,\n",
    "        nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "        outputs=[diag_output_filename],\n",
    "        parser_outputs=[{\"name\": \"eigvals\"}],\n",
    "    )\n",
    "\n",
    "    @task.calcfunction\n",
    "    def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "        node = orm.Float(np.mean(eigenvalues.get_array()))\n",
    "        node.attributes[\"length\"] = len(eigenvalues)\n",
    "        return node\n",
    "\n",
    "    # TODO add compute_mean\n",
    "\n",
    "    return wg\n",
    "\n",
    "\n",
    "wg = WorkGraph()\n",
    "wg.add_task(query_and_diag)\n",
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "for i in range(1, 5):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to collect all the results and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO you don't have to compute anymore the mean value because it is exposed by the graph_builder\n",
    "@task.calcfunction\n",
    "def assemble_plot(**collected_eigvals) -> dict[str, orm.Data]:\n",
    "    # return orm.List([arr.get_array() for arr in x.values()])\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    label: str\n",
    "    eigval_data: orm.ArrayData\n",
    "    mean_eigenvalues = []\n",
    "    for _, eigval_data in collected_eigvals.items():\n",
    "        mean_eigenvalues.append(np.mean(eigval_data.get_array()))\n",
    "    ax.hist(mean_eigenvalues, bins=10, color=\"c\", edgecolor=\"black\")\n",
    "    ax.set_title(\"Histogram of Eigenvalues\")\n",
    "    ax.set_xlabel(\"Eigenvalue\")\n",
    "    filename = \"plot.jpg\"\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    return orm.SinglefileData(Path(filename).absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"processing_data\")\n",
    "assemble_plot_task = wg.add_task(assemble_plot, name=\"assemble_plot_task\")\n",
    "# we have to increase the link limit because by default workgraph only supports one link per input socket\n",
    "assemble_plot_task.inputs[\"collected_eigvals\"].link_limit = 50\n",
    "for i in range(1, 10):\n",
    "    query_and_diag_task = wg.add_task(\n",
    "        query_and_diag, name=f\"query_and_diag_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "    wg.add_link(\n",
    "        query_and_diag_task.outputs[\"eigvals\"],\n",
    "        assemble_plot_task.inputs[\"collected_eigvals\"],\n",
    "    )\n",
    "display(wg)\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QueryBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can query now from our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also introduce filters in our queriesS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO QueryBuilder expand plot something\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.ArrayData,\n",
    "    filters={\n",
    "        'attributes.length': {'==': 50}\n",
    "    },\n",
    "    project=['attributes.array|default']\n",
    ")\n",
    "qb.all(flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we create if conditions workflows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def compute_mean(eigvals: orm.ArrayData) -> orm.Float:\n",
    "    return orm.Float(np.mean(eigvals.get_array()))\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def eigvals_less(mean_eigval: orm.Float) -> bool:\n",
    "    return mean_eigval < 14.5\n",
    "\n",
    "\n",
    "@task.calcfunction\n",
    "def heureka(eigvals, pk):\n",
    "    try:\n",
    "        path = Path(\"storage\").absolute()\n",
    "        path.mkdir(exist_ok=True)\n",
    "        result_path = path / f\"eigvals-pk{pk}.npy\"\n",
    "        np.save(result_path, eigvals.get_array())\n",
    "        success = orm.Int(0)\n",
    "        success.attributes[\"path\"] = str(result_path)\n",
    "        success.attributes[\"error\"] = \"\"\n",
    "    except Exception as err:\n",
    "        success = orm.Int(1)\n",
    "        success.attributes[\"path\"] = \"\"\n",
    "        success.attributes[\"error\"] = str(err)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"someother\")\n",
    "\n",
    "martix_pk = 5\n",
    "\n",
    "query_and_diag_task = wg.add_task(\n",
    "    query_and_diag, name=f\"query_and_diag_pk{matrix_pk}\", matrix_pk=orm.Int(matrix_pk)\n",
    ")\n",
    "compute_mean_task = wg.add_task(\n",
    "    compute_mean,\n",
    "    name=f\"compute_mean_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    ")\n",
    "eigvals_less_task = wg.add_task(\n",
    "    eigvals_less,\n",
    "    name=f\"eigvals_less_task_pk{matrix_pk}\",\n",
    "    mean_eigval=compute_mean_task.outputs[\"result\"],\n",
    ")\n",
    "if_less = wg.add_task(\n",
    "    \"If\", name=f\"if_less_pk{matrix_pk}\", conditions=eigvals_less_task.outputs[\"result\"]\n",
    ")  # there as specific conditions socket\n",
    "heureka_task = wg.add_task(\n",
    "    heureka,\n",
    "    name=f\"heureka_task_pk{matrix_pk}\",\n",
    "    eigvals=query_and_diag_task.outputs[\"eigvals\"],\n",
    "    pk=orm.Int(i),\n",
    ")\n",
    "if_less.children.add(f\"heureka_task_pk{matrix_pk}\")\n",
    "\n",
    "display(wg)\n",
    "wg.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
