{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create more complex workflows\n",
    "\n",
    "**Please note, this notebook depends on successful execution of the first notebook `1-aiida-intro.ipynb`!**\n",
    "\n",
    "In the previous notebook, we have seen how we can run arbitrary executables through `aiida-shell` without requiring any\n",
    "code-specific infrastructure (typically contained in a dedicated AiiDA plugin). In addition, we have seen how we can\n",
    "feed the output of one task to the input of another task, linking the two and effectively creating a workflow.\n",
    "\n",
    "Building on this concept, the `aiida-workgraph` provides the capability to create workflows in the same manner as one would\n",
    "build up an actual graph. That is, by adding nodes and edges to it. It further extends the possible building blocks for\n",
    "our workflow from\n",
    "external scripts (as seen with `aiida-shell`) to other AiiDA buliding blocks (`CalcFunction`s, `CalcJob`s, `WorkChain`s, etc.), as well as custom\n",
    "Python code.\n",
    "\n",
    "We'll cover lots of material in this notebook, so strap yourself in and buckle up! :rocket:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "To run the following Python cells, we need to make sure that we select the correct kernel `Python3.10 (AIIDA)`. If it is\n",
    "not already selected, do so as follows:\n",
    "\n",
    "<img src=\"../../data/figs/change_notebook_kernel.png\" width=\"500\" style=\"height:auto; display:block; margin-left:auto; margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the AiiDA jupyter notebook extension, check the profile status, import the libraries all that we need. So nothing new\n",
    "here, really..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T09:59:16.752276Z",
     "start_time": "2024-08-26T09:59:15.256934Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T09:59:19.958648Z",
     "start_time": "2024-08-26T09:59:19.470797Z"
    }
   },
   "outputs": [],
   "source": [
    "%verdi status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T09:59:29.401931Z",
     "start_time": "2024-08-26T09:59:28.274294Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from aiida import orm\n",
    "from aiida_shell.parsers import ShellParser\n",
    "from aiida.tools.visualization import Graph\n",
    "\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "from aiida_workgraph.utils import generate_node_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T09:59:55.471429Z",
     "start_time": "2024-08-26T09:59:55.012960Z"
    }
   },
   "outputs": [],
   "source": [
    "diag_code = orm.load_code('diagonalization@localhost')  # The computer label can also be omitted here\n",
    "query_code = orm.load_code('remote_query@localhost')  # The computer label can also be omitted here\n",
    "db_path = str(Path('../../data/euro-scipy-2024/diag-wf/remote/matrices.db').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:00:07.856511Z",
     "start_time": "2024-08-26T10:00:07.848828Z"
    }
   },
   "outputs": [],
   "source": [
    "def provenance_graph(aiida_node):\n",
    "    graph = Graph()\n",
    "    graph.recurse_ancestors(aiida_node, annotate_links=\"both\")\n",
    "    graph.recurse_descendants(aiida_node, annotate_links=\"both\")\n",
    "    display(graph.graphviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkGraph vs. provenance graph\n",
    "\n",
    "As evident from the import statement:\n",
    "\n",
    "```python\n",
    "from aiida_workgraph import WorkGraph, task\n",
    "```\n",
    "\n",
    "the first entity we'll be using is, of course, the `WorkGraph`. In addition, we import the `task`, which actually\n",
    "presents the `WorkGraph` equivalent of a *node* in the graphs we'll be building up.\n",
    "\n",
    "In line with common graph nomenclature, we'd have loved to use the **Node** keyword for that, but remember, the `Node`\n",
    "class is already defined in `aiida-core`. To avoid confusion, it is good to mention here, that we will now be talking\n",
    "about two different kinds of graphs:\n",
    "- **The provenance graph**: AiiDA's way of storing the **Data** and **Processes** inside the SQL database as **Node**s\n",
    "  and **Link**\n",
    "- **The WorkGraph**: The workflow we are building up using the `aiida-workgraph` library\n",
    "\n",
    "As such, we can build up our workflow as a **WorkGraph**, run it, and AiiDA will store all data in its database, allowing\n",
    "us to explore the resulting **provenance graph** of our workflow.\n",
    "\n",
    "Let's maybe best start with some simple examples, this will make things clear. We'll close the cycle to the previous\n",
    "notebook in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:01:30.437206Z",
     "start_time": "2024-08-26T10:01:30.316336Z"
    }
   },
   "outputs": [],
   "source": [
    "def sleep_and_print(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time)\n",
    "    print(print_statement)\n",
    "\n",
    "wg = WorkGraph('First WG')\n",
    "\n",
    "wg.add_task(sleep_and_print)\n",
    "wg.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you just created your first `WorkGraph`! Let's unpack the code: We first created a very simple Python\n",
    "function, we then instantiated the `WorkGraph`, and added our function as a task (remember, think of *graph nodes*).\n",
    "\n",
    "`aiida-workgraph` comes with a visualization tool in which we can see the setup of our workflow. Note that we didn't\n",
    "actually run it at this point, yet. Let's add a second task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:01:35.652665Z",
     "start_time": "2024-08-26T10:01:35.571886Z"
    }
   },
   "outputs": [],
   "source": [
    "wg.add_task(sleep_and_print)\n",
    "wg.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we now have two disconnected tasks in our workgraph. To define dependencies between those, we can either\n",
    "link inputs and outpus, just as we did before with `aiida-shell`, or explicitly enforce that the second task has to wait\n",
    "on the first one. For now, let's actually focus on the second case (the first one will require us to introduce a few\n",
    "more concepts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:02:18.175480Z",
     "start_time": "2024-08-26T10:02:18.156892Z"
    }
   },
   "outputs": [],
   "source": [
    "wg.tasks.sleep_and_print2.waiting_on.add('sleep_and_print1')\n",
    "wg.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we accessed the second task through our `WorkGraph` instance, `wg`. However, the `add_task` function\n",
    "actually returns the task, so we can also write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:02:47.315836Z",
     "start_time": "2024-08-26T10:02:47.155960Z"
    }
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph('First WG')\n",
    "\n",
    "task1 = wg.add_task(sleep_and_print)\n",
    "task2 = wg.add_task(sleep_and_print)\n",
    "\n",
    "task2.waiting_on.add('sleep_and_print1')\n",
    "wg.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which achieves the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Python code with WorkGraph and AiiDA provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we want to actually run our workflow, we should specify some inputs to our tasks. We can do that, as well as name our\n",
    "tasks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:03:20.026035Z",
     "start_time": "2024-08-26T10:03:17.530189Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"Run WG\")\n",
    "\n",
    "task_without_provenance = wg.add_task(\n",
    "    sleep_and_print, name=\"lets_start\",\n",
    "    sleep_time=1,\n",
    "    print_statement=\"Let's start\"\n",
    ")\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like everything worked out smoothly. Now, let's show the provenance graph of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:04:08.971682Z",
     "start_time": "2024-08-26T10:04:08.780508Z"
    }
   },
   "outputs": [],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where are our tasks? :anguished:\n",
    "\n",
    "It is important to note here that AiiDA does not store the plain Python function we used to define our tasks in its\n",
    "database. Remember, the AiiDA classes derived from `Node` implement this functionality, so AiiDA doesn't know how to\n",
    "store the data in the database.  Thankfully, we can easily resolve this issue by adding AiiDA `orm.Data` types as inputs\n",
    "to the task, so we access their actual `value`s inside the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:07:06.856579Z",
     "start_time": "2024-08-26T10:07:06.846066Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example for aiida.orm.Data types\n",
    "print(orm.Int(1))\n",
    "print(orm.Int(1).value) # get your int value back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:07:09.588844Z",
     "start_time": "2024-08-26T10:07:07.088972Z"
    }
   },
   "outputs": [],
   "source": [
    "def sleep_and_print_with_provenance(sleep_time, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    print(print_statement.value)\n",
    "\n",
    "wg = WorkGraph(\"Provenance restored\")\n",
    "\n",
    "task_with_provenance = wg.add_task(\n",
    "    sleep_and_print_with_provenance, name=\"lets_start\",\n",
    "    sleep_time=orm.Int(1), # <-- Note this change\n",
    "    print_statement=orm.Str(\"Let's start\") # Note this change\n",
    ")\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:05:50.001020Z",
     "start_time": "2024-08-26T10:05:49.786576Z"
    }
   },
   "outputs": [],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On creating, returning, and linking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we would like to specify data dependencies, we should define a `task.calcfunction` that actually\n",
    "returns some output so that we can then link it as an input to another task (before, we were only printing).\n",
    "\n",
    "The function in the next cell achieves just that. Here, we have manually specified our `outputs` in the decorator, and\n",
    "we return a clone of the `print_statement`, as returning the actual data node would create a cycle in the graph, which\n",
    "is forbidden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:12:48.665583Z",
     "start_time": "2024-08-26T10:12:44.606683Z"
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction(\n",
    "    outputs=[\n",
    "        {'name': 'result', 'identifier': orm.Str}\n",
    "    ]\n",
    ")\n",
    "def sleep_and_return(sleep_time: orm.Int, print_statement):\n",
    "    time.sleep(sleep_time.value)\n",
    "    return {'result': orm.Str(print_statement.value)}\n",
    "\n",
    "\n",
    "wg = WorkGraph(\"Linked data\")\n",
    "\n",
    "another_task_with_provenance = wg.add_task(\n",
    "    sleep_and_return, name=\"actual_print_task\",\n",
    "    sleep_time=orm.Int(1),\n",
    "    print_statement=orm.Str(\"I will print the previous return\")\n",
    ")\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WorkGraph by default does not show the output sockets if they are not linked to other tasks, but we can see it when plotting directly the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:13:08.012948Z",
     "start_time": "2024-08-26T10:13:07.993353Z"
    }
   },
   "outputs": [],
   "source": [
    "another_task_with_provenance.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a number of other sockets workgraph uses in the background. Note that the workgraph uses always _result_ as default output socket for the return value of the function if nothing else is specified. Now lets look at the provenance graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:13:30.839916Z",
     "start_time": "2024-08-26T10:13:30.632542Z"
    }
   },
   "outputs": [],
   "source": [
    "provenance_graph(aiida_node=wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now also the output is part of the provenance graph. With this, we can now define (almost) arbitrarily complex workflows, as shown below. Feel free to play around with this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:14:59.195247Z",
     "start_time": "2024-08-26T10:14:42.190307Z"
    }
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"Arbitrary WorkGraph\")\n",
    "\n",
    "task1 = wg.add_task(\n",
    "    sleep_and_print_with_provenance, name=\"lets_start\", sleep_time=orm.Int(1), print_statement=orm.Str(\"Let's start\")\n",
    ")\n",
    "\n",
    "task2 = wg.add_task(\n",
    "    sleep_and_print_with_provenance,\n",
    "    name=\"lets_continue\",\n",
    "    sleep_time=orm.Int(1),\n",
    "    print_statement=orm.Str(\"Let's continue\"),\n",
    ")\n",
    "\n",
    "task2.waiting_on.add(\"lets_start\")\n",
    "\n",
    "task3 = wg.add_task(\n",
    "    sleep_and_print_with_provenance,\n",
    "    name=\"wait_both\",\n",
    "    sleep_time=orm.Int(1),\n",
    "    print_statement=orm.Str(\"I need to wait for both\"),\n",
    ")\n",
    "\n",
    "task3.waiting_on.add(\"lets_start\")\n",
    "task3.waiting_on.add(\"lets_continue\")\n",
    "\n",
    "disconnected_task = wg.add_task(\n",
    "    sleep_and_print_with_provenance,\n",
    "    name=\"disconnected_task\",\n",
    "    sleep_time=orm.Int(5),\n",
    "    print_statement=orm.Str(\"I have no dependencies, but I am one, and I take my time.\"),\n",
    ")\n",
    "\n",
    "task4 = wg.add_task(\n",
    "    sleep_and_return,\n",
    "    name=\"intermediate_step\",\n",
    "    sleep_time=orm.Int(1),\n",
    "    print_statement=orm.Str(\"I will print the previous return.\"),\n",
    ")\n",
    "\n",
    "task4.waiting_on.add(\"disconnected_task\")\n",
    "task4.waiting_on.add(\"wait_both\")\n",
    "\n",
    "task5 = wg.add_task(\n",
    "    sleep_and_print_with_provenance,\n",
    "    name=\"final_step\",\n",
    "    sleep_time=orm.Int(1),\n",
    "    print_statement=task4.outputs[\"result\"],\n",
    ")\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the circle: Back to the `aiida-shell` example\n",
    "\n",
    "Now that we have seen how we can construct simple workflows and define task dependencies with the `WorkGraph`, let's use\n",
    "it to implement the workflow from the previous notebook. The code snippets in the following cells are rather lengthy,\n",
    "however, the way we execute the external executable is the same as before, just that we now add a `ShellJob` `task` to\n",
    "the `WorkGraph` (passing the same arguments as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:18:28.546446Z",
     "start_time": "2024-08-26T10:18:28.442660Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"query_and_diag\")\n",
    "\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_code,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "# The file name automatically gets converted into an AiiDA link label by `aiida-shell`\n",
    "# Link labels can only have alphanumericy characters and underscores, so we apply the same cleaning to the filename\n",
    "# To be able to reference it later on\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching a parser\n",
    "\n",
    "Now that we have run the query task as before, the next step is the diagonalization. However, we might not only want to\n",
    "write the eigenvalues to an output file, but also parse them, e.g. so that the resulting array is stored\n",
    "**explicitly** in AiiDA's database (rather than just a reference to the file), and so that we can further operate on it\n",
    "directly in our Python code. To achieve that, we define a parser function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:18:29.707597Z",
     "start_time": "2024-08-26T10:18:29.700001Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_array(self, dirpath: Path) -> dict[str, orm.Data]:\n",
    "    arr = np.loadtxt(dirpath / self.node.inputs.outputs[0])\n",
    "    data = orm.ArrayData(arr)\n",
    "    return {\"eigvals\": data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can now pass to our diagonalization task via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:20:55.957887Z",
     "start_time": "2024-08-26T10:20:35.414243Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_code,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    # Attach parser here\n",
    "    parser=parse_array,\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now allows us to retrieve the eigenvalue outputs directly from the associated AiiDA `Node` attached to the\n",
    "`WorkGraph` `Task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:22:55.866634Z",
     "start_time": "2024-08-26T10:22:55.818912Z"
    }
   },
   "outputs": [],
   "source": [
    "print(diag_task.outputs[\"eigvals\"])\n",
    "print(diag_task.outputs[\"eigvals\"].value)\n",
    "print(diag_task.outputs[\"eigvals\"].value.get_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go back one more time to see the provenance, now that we are more familiar with the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:23:34.499032Z",
     "start_time": "2024-08-26T10:23:34.057804Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "provenance_graph(wg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending WorkGraph with arbitrary python code\n",
    "\n",
    "As we have seen in the simple examples in the beginning of this notebook, we can set up tasks using any Python code.\n",
    "This is part of what makes AiiDA workflows so powerful. You can do literally anything!\n",
    "\n",
    "Using Python code as steps of your workflow is also the native way of defining a workflow in AiiDA through writing\n",
    "`WorkChain`s, and not a feature of the `WorkGraph`. However, the `WorkGraph` provides a simplified interface for\n",
    "defining workflows.\n",
    "\n",
    "Let's instantiate a new empty `WorkGraph` and add our previous task, as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:29:51.871507Z",
     "start_time": "2024-08-26T10:29:51.765347Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"compute_eigvals_wg\")\n",
    "matrix_pk = 5\n",
    "query_output_filename = f\"matrix-{matrix_pk}.npy\"\n",
    "\n",
    "query_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"query_task\",\n",
    "    command=query_code,\n",
    "    arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "    nodes={\"db_path\": db_path, \"matrix_pk\": orm.Int(matrix_pk)},\n",
    "    outputs=[query_output_filename],\n",
    ")\n",
    "\n",
    "query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "diag_output_filename = f\"matrix-{matrix_pk}-eigvals.txt\"\n",
    "\n",
    "diag_task = wg.add_task(\n",
    "    \"ShellJob\",\n",
    "    name=\"diag_task\",\n",
    "    command=diag_code,\n",
    "    arguments=[\"{matrix_file}\"],\n",
    "    parser=parse_array,\n",
    "    nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "    outputs=[diag_output_filename],\n",
    "    parser_outputs=[{\"name\": \"eigvals\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a `calcfunction` to calculate the mean of the eigenvalues and add it to our `WorkGraph`.\n",
    "\n",
    "(Remember, a `calcfunction` is an AiiDA process that uses ORM data types, and thus is stored in the database and the\n",
    "provenance graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:30:22.817366Z",
     "start_time": "2024-08-26T10:29:52.493351Z"
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData):\n",
    "    return {\"result\": orm.Float(np.mean(eigenvalues.get_array()))}\n",
    "\n",
    "\n",
    "mean_task = wg.add_task(\n",
    "    compute_mean, name=\"mean_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    ")\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, as before, just passing the undecorated `compute_mean` Python function would, in principle, work, however, no\n",
    "provenance would be recorded. It is still allowed, as one might want to execute a step in the workflow that should not\n",
    "be recorded in the provenance.\n",
    "\n",
    "Workgraph uses outputs sockets that store the property, so we can retrieve the `orm.Float` by taking the `value` of the socket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:32:01.254874Z",
     "start_time": "2024-08-26T10:32:01.233161Z"
    }
   },
   "outputs": [],
   "source": [
    "print(wg.tasks[\"mean_task\"].outputs[\"result\"]) # output socket result\n",
    "print(wg.tasks[\"mean_task\"].outputs[\"result\"].value) # resulting orm.Float\n",
    "print(wg.tasks[\"mean_task\"].outputs[\"result\"].value.value) # resulting orm.Float value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining tasks with the `graph_builder`\n",
    "\n",
    "As we have seen above, when generating multiple workgraphs with the same steps (e.g. query and diagonalization), we\n",
    "always need to repeat the code used to add the tasks when we create new `WorkGraph`s. This is quite cumbersome\n",
    "and will lead to unwanted code repetition. For this purpose, the `aiida-workgraph` provides the `graph_builder`, which\n",
    "allows one to merge together multiple tasks into one entity, thus enabling the creation of complex, nested `WorkGraph`s. \n",
    "\n",
    "The following cell combines the code from the querying, diagonalization, and calculation of the mean into one reusable\n",
    "`query_diag_mean` entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:35:55.195116Z",
     "start_time": "2024-08-26T10:35:55.028187Z"
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "    eigenvalues_arr = eigenvalues.get_array()\n",
    "    node = orm.Float(np.mean(eigenvalues_arr))\n",
    "    node.attributes[\"length\"] = len(\n",
    "        eigenvalues_arr\n",
    "    )  # Note this change, we will discuss this later\n",
    "    return node\n",
    "\n",
    "\n",
    "@task.graph_builder(\n",
    "    outputs=[\n",
    "        {\n",
    "            \"name\": \"eigvals\",\n",
    "            \"from\": \"diag_task.eigvals\",\n",
    "        },  # exposes output `eigvals` of task diag_task under the name `eigvals`\n",
    "        {\n",
    "            \"name\": \"mean_eigval\",\n",
    "            \"from\": \"mean_task.result\",\n",
    "        },  # exposes output `result` of task mean_task under the name `mean_eigval`\n",
    "    ]\n",
    ")\n",
    "def query_diag_mean(matrix_pk: orm.Int):\n",
    "    global db_path\n",
    "    wg = WorkGraph()\n",
    "    query_output_filename = f\"matrix-{matrix_pk.value}.npy\"\n",
    "\n",
    "    query_code = orm.load_code(\"remote_query@localhost\")\n",
    "    query_task = wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"query_task\",\n",
    "        command=query_code,\n",
    "        arguments=[\"{db_path}\", \"{matrix_pk}\"],\n",
    "        nodes={\n",
    "            \"db_path\": db_path,\n",
    "            \"matrix_pk\": matrix_pk,\n",
    "        },\n",
    "        outputs=[query_output_filename],\n",
    "    )\n",
    "\n",
    "    query_task_link_label = ShellParser.format_link_label(query_output_filename)\n",
    "    diag_code = orm.load_code(\"diagonalization@localhost\")\n",
    "    diag_output_filename = f\"matrix-{matrix_pk.value}-eigvals.txt\"\n",
    "\n",
    "    diag_task = wg.add_task(\n",
    "        \"ShellJob\",\n",
    "        name=\"diag_task\",\n",
    "        command=diag_code,\n",
    "        arguments=[\"{matrix_file}\"],\n",
    "        nodes={\"matrix_file\": query_task.outputs[query_task_link_label]},\n",
    "        outputs=[diag_output_filename],\n",
    "        parser=parse_array,\n",
    "        parser_outputs=[{\"name\": \"eigvals\"}],\n",
    "    )\n",
    "\n",
    "    wg.add_task(\n",
    "        compute_mean, name=\"mean_task\", eigenvalues=diag_task.outputs[\"eigvals\"]\n",
    "    )\n",
    "\n",
    "    return wg\n",
    "\n",
    "\n",
    "wg = WorkGraph()\n",
    "# Here we add the collection of tasks defined previously via the `graph_builder` as one single task\n",
    "query_diag_mean_task = wg.add_task(query_diag_mean, name=\"query_diag_mean\")\n",
    "wg.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the three tasks are now encapsulated into one step. When we have a look at the task we can see that the specifed outputs are also exposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:36:18.339504Z",
     "start_time": "2024-08-26T10:36:18.324818Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_diag_mean_task.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this `WorkGraph` task to run it in a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:43:34.235410Z",
     "start_time": "2024-08-26T10:40:17.703329Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"query_diag_mean_wg\")\n",
    "for i in range(5):\n",
    "    query_diag_mean_task = wg.add_task(\n",
    "        query_diag_mean, name=f\"query_diag_mean_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the computation is running you might want to have look at `watch -n 1 \"verdi process list\"` in another terminal or\n",
    "notebook to see the calculations running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating results\n",
    "\n",
    "We have now seen how we can use the `graph_builder` to generate reusable multi-step `WorkGraph` components. Assume we\n",
    "would now like to aggregate all results from running this component various times, and e.g. create a plot from the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:44:36.808156Z",
     "start_time": "2024-08-26T10:44:36.739689Z"
    }
   },
   "outputs": [],
   "source": [
    "@task.calcfunction\n",
    "def aggregate_to_plot(\n",
    "    **collected_mean_eigvals: dict[str, orm.Float]\n",
    ") -> dict[str, orm.Data]:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    collected_mean_eigenvalues_list = [\n",
    "        orm_float.value for orm_float in collected_mean_eigvals.values()\n",
    "    ]\n",
    "    ax.hist(collected_mean_eigenvalues_list, bins=10, color=\"c\", edgecolor=\"black\")\n",
    "    ax.set_title(\"Histogram of Eigenvalues\")\n",
    "    ax.set_xlabel(\"Eigenvalue\")\n",
    "    filename = \"plot.jpg\"\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    return orm.SinglefileData(Path(filename).absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:46:35.964443Z",
     "start_time": "2024-08-26T10:44:38.407079Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"plot_mean_eigenvalues\")\n",
    "\n",
    "aggregate_to_plot_task = wg.add_task(aggregate_to_plot, name=\"aggregate_to_plot_task\")\n",
    "\n",
    "# we have to increase the link limit because by default workgraph only supports one link per input socket\n",
    "max_query_pk = 3\n",
    "aggregate_to_plot_task.inputs[\"collected_mean_eigvals\"].link_limit = max_query_pk\n",
    "\n",
    "for i in range(max_query_pk):\n",
    "    query_diag_mean_task = wg.add_task(\n",
    "        query_diag_mean, name=f\"query_diag_mean_pk{i}\", matrix_pk=orm.Int(i)\n",
    "    )\n",
    "    # We create a `link` between the output of the `query_diag_mean` task and the input of the aggregation and plot task\n",
    "    wg.add_link(\n",
    "        query_diag_mean_task.outputs[\"mean_eigval\"],\n",
    "        aggregate_to_plot_task.inputs[\"collected_mean_eigvals\"],\n",
    "    )\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: QueryBuilder with node attributes\n",
    "\n",
    "A little detail you might have spotted: When defining the `query_diag_mean` `graph_builder`, we actually added an\n",
    "attribute to the `orm.Float` entity that attaches the mean eigenvalue.\n",
    "\n",
    "```python\n",
    "@task.calcfunction\n",
    "def compute_mean(eigenvalues: orm.ArrayData) -> dict[str, orm.Data]:\n",
    "    eigenvalues_arr = eigenvalues.get_array()\n",
    "    node = orm.Float(np.mean(eigenvalues_arr))\n",
    "    node.attributes[\"length\"] = len(eigenvalues_arr) # Note this change, we will discuss this later\n",
    "    return node\n",
    "```\n",
    "\n",
    "We will now show how to query for this attribute after we collected several calculations. As we have seen in the\n",
    "previous notebook, a regular query for the a specific data type can be constructed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:46:36.167153Z",
     "start_time": "2024-08-26T10:46:36.064019Z"
    }
   },
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "\n",
    "qb.append(orm.Float)\n",
    "\n",
    "print(\"Number of entries: \", len(qb.all()))\n",
    "print(\"First entry: \", qb.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we get a list of lists because we can `project` different properties of the object for retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:46:58.370086Z",
     "start_time": "2024-08-26T10:46:58.333932Z"
    }
   },
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.Float,\n",
    "    project=['uuid', 'attributes.value', 'attributes.length']\n",
    ")\n",
    "print(\"Number of entries: \", len(qb.all()))\n",
    "print(\"First entry value and length: \", qb.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the previous calculations we added the attribute length we now filter for certain lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:47:52.560561Z",
     "start_time": "2024-08-26T10:47:52.509766Z"
    }
   },
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.Float,\n",
    "    filters=orm.Float.fields.attributes[\"length\"].in_(\n",
    "        [49, 50, 51]\n",
    "    ),  # This is the attribute we have set in the `compute_mean` calcfunction\n",
    "    project=[\"attributes.value\", \"attributes.length\"],\n",
    ")\n",
    "print(\"Number of entries: \", len(qb.all()))\n",
    "print(\"First entry value and length: \", qb.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also add logical operations like filtering below a specific value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:48:46.744767Z",
     "start_time": "2024-08-26T10:48:46.709725Z"
    }
   },
   "outputs": [],
   "source": [
    "qb = orm.QueryBuilder()\n",
    "qb.append(\n",
    "    orm.Float,\n",
    "    filters=(\n",
    "        (orm.Float.fields.attributes[\"length\"].in_([49, 50, 51]))\n",
    "        & (orm.Float.fields.value < 14.5)\n",
    "    ),\n",
    "    project=[\"attributes.value\", \"attributes.length\"],\n",
    ")\n",
    "print(\"Number of entries: \", len(qb.all()))\n",
    "print(\"First entry value and length: \", qb.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our little interlude on AiiDA's `QueryBuilder`. We have introduced some concepts that are necessary\n",
    "for the next and final section of this tutorial notebook. Just keep in mind that the `QueryBuilder` is an extremely\n",
    "powerful tool that lets you construct (almost) arbitrarily complex queries on your database. More information can be\n",
    "found in the documentation, e.g.\n",
    "[here](https://aiida.readthedocs.io/projects/aiida-core/en/latest/howto/query.html#how-to-find-and-query-for-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we incorporate if conditions in `WorkGraph` workflows?\n",
    "\n",
    "An if condition changes the type of task that is executed and the type of output that is passed through the upcoming\n",
    "tasks and therefore needs additional logic in the workflow manager to be handled properly. We take an example from\n",
    "material science where we are often interested in structures that correspond to very low eigenvalues as these structures\n",
    "are more stable (there are more subtleties we ignore for the sake of simplicity). Let us filter out the matrices with an\n",
    "eigenvalue below a threshold of 14.5 and incorporate this selection into the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:50:13.267883Z",
     "start_time": "2024-08-26T10:50:13.182375Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the condition task that will be used in the if task\n",
    "@task.calcfunction\n",
    "def eigvals_less(mean_eigval: orm.Float) -> bool:\n",
    "    return mean_eigval < 14.5\n",
    "\n",
    "# When we found a right candidate we can celebrate\n",
    "@task.calcfunction\n",
    "def heureka(eigvals, pk):\n",
    "    print(\"Heureka we found a new stable material, lets publish in Nature!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T10:52:09.130582Z",
     "start_time": "2024-08-26T10:50:49.122190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wg = WorkGraph(\"matrix_discovery\")\n",
    "\n",
    "for matrix_pk in [1, 5]:\n",
    "    query_diag_mean_task = wg.add_task(\n",
    "        query_diag_mean,\n",
    "        name=f\"query_diag_mean_pk{matrix_pk}\",\n",
    "        matrix_pk=orm.Int(matrix_pk),\n",
    "    )\n",
    "    eigvals_less_task = wg.add_task(\n",
    "        eigvals_less,\n",
    "        name=f\"eigvals_less_task_pk{matrix_pk}\",\n",
    "        mean_eigval=query_diag_mean_task.outputs[\"mean_eigval\"],\n",
    "    )\n",
    "    if_less = wg.add_task(\n",
    "        \"If\",  # Note that this is an identifier that marks this to be an If task\n",
    "        name=f\"if_less_pk{matrix_pk}\",\n",
    "        conditions=eigvals_less_task.outputs[\"result\"],  # An If task has this attribute\n",
    "    )\n",
    "\n",
    "    heureka_task = wg.add_task(\n",
    "        heureka,\n",
    "        name=f\"heureka_task_pk{matrix_pk}\",\n",
    "        eigvals=query_diag_mean_task.outputs[\"eigvals\"],\n",
    "        pk=orm.Int(i),\n",
    "    )\n",
    "    if_less.children.add(\n",
    "        f\"heureka_task_pk{matrix_pk}\"\n",
    "    )  # this adds the task to the if condition\n",
    "\n",
    "    # To create at task for the case the condition is false, one can use `invert_condition=True`\n",
    "    if_greater_equal = wg.add_task(\n",
    "        \"If\",\n",
    "        name=f\"if_greater_equal_pk{matrix_pk}\",\n",
    "        conditions=eigvals_less_task.outputs[\"result\"],\n",
    "        invert_condition=True\n",
    "    )\n",
    "\n",
    "display(wg.to_html())\n",
    "wg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for `PK<1>` the if condition was fulfilled while for `PK<5>` it was not so the heureka task was not executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matrix_pk in [1, 5]:\n",
    "    print(\n",
    "        f\"Mean eigval for martix PK <{matrix_pk}>: \",\n",
    "        wg.tasks[f\"query_diag_mean_pk{matrix_pk}\"].outputs[\"mean_eigval\"].value.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be mentioned that, while the `WorkGraph` provides a simplified interface for writing AiiDA workflows, for very\n",
    "complex setups, writing a `WorkChain` class with arbitrary Python code might actually be the preferred approach.\n",
    "Always evaluate your requirements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, congratulations! You can now call yourself a `WorkGraph` expert.\n",
    "\n",
    "Just like we did for the hero run, you have thus acquired the power to fill your entire HPC cluster with AiiDA workflows\n",
    "that keep full provenance of your data (but please don't ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (AIIDA)",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
