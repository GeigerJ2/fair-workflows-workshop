{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing your own workflow - Equation of State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will construct our own workflow to calculate the **Equation of State** (EOS). We will again start with\n",
    "the necessary preparations, such as creating the structure, loading the code, defining the calculation paremeters, and\n",
    "metadata options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext aiida\n",
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import engine, orm\n",
    "from aiida_quantumespresso.calculations.pw import PwCalculation\n",
    "from ase.build import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the label here to 7.1 when running on nanoHUB\n",
    "pw_code = orm.load_code('qe-7.3-pw@localhost')\n",
    "si_structure = orm.StructureData(ase=bulk('Si', 'diamond', a=5.43)).store()\n",
    "\n",
    "kpoints = orm.KpointsData()\n",
    "kpoints.set_kpoints_mesh([2, 2, 2])\n",
    "\n",
    "pseudo_family = orm.load_group('SSSP/1.3/PBEsol/efficiency')\n",
    "\n",
    "cutoff_wfc, cutoff_rho = pseudo_family.get_recommended_cutoffs(\n",
    "    structure=si_structure,\n",
    "    unit='Ry'\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'CONTROL': {\n",
    "        'calculation': 'scf',\n",
    "    },\n",
    "    'SYSTEM': {\n",
    "        'occupations': 'smearing',\n",
    "        'smearing': 'cold',\n",
    "        'degauss': 0.02\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_options = {\n",
    "    \"resources\": {\n",
    "        \"num_machines\": 1\n",
    "    },\n",
    "    \"max_wallclock_seconds\": 1800,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Now, let's consider the different steps that our workflow should compose:\n",
    "1. Take an input structure and scale it to both compress and expand it\n",
    "2. Calculate the SCF energies for all scaled structures\n",
    "3. Plot the obtained results\n",
    "\n",
    "Ideally, one would also relax the input structure for scaling, but for simplicity we will omit this step here.\n",
    "\n",
    "Before going to the actual implementation, it is good to reiterate some of AiiDA's main concepts:\n",
    "\n",
    "- **Provenance**: AiiDA tracks all data and processes in a provenance graph. To achieve this, data must be in the form\n",
    "  of AiiDA data types, such as `Int`, `Float`, `StructureData`. This is because these classes inherit from the `Node`\n",
    "  base class, which contains the functionality to store the data in the database and record the provenance.\n",
    "- **Calcfunctions**: To run operations that create data, the corresponding Python functions must be converted into AiiDA\n",
    "  `calcfunction`s, which can be achieved with the `@engine.calcfunction` decorator. It's important to note here, that,\n",
    "  to keep provenance, these functions need to take AiiDA data `Node`s as inputs and return those as outputs.\n",
    "- **WorkChains**: To define workflows in AiiDA one has to define a `WorkChain`, which contains the logic of the\n",
    "  workflow. However, as opposed to `calcfunction`s, `WorkChain`s cannot create data. As such, all data creation has to\n",
    "  be handled by `calcfunction`s instead, while the `WorkChain` can only *return* the existing data.\n",
    "\n",
    "With this, let's generate the `calcfunction` to scale the structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@engine.calcfunction\n",
    "def scale_structures(\n",
    "    structure: orm.StructureData,  # AiiDA StructureData passed rather than ase.Atoms, which we will obtain internally\n",
    "    factor_list: orm.List,  # AiiDA orm.List passed, the Python list will be obtained internally for the iteration\n",
    "    ):\n",
    "\n",
    "    scaled_structure_dict = {}\n",
    "\n",
    "    for index, scaling_factor in enumerate(factor_list.get_list()):\n",
    "\n",
    "        # Here we obtain the ase.Atoms object which we can modify\n",
    "        # Note that the StructureData cannot be directly scaled, as it is immutable to keep provenance\n",
    "        ase_structure = structure.get_ase()\n",
    "\n",
    "        # Scale the ase.Atoms object\n",
    "        new_cell = ase_structure.get_cell() * scaling_factor\n",
    "        ase_structure.set_cell(new_cell, scale_atoms=True)\n",
    "\n",
    "        scaled_structure_dict[f'structure_{index}'] = orm.StructureData(ase=ase_structure)\n",
    "\n",
    "    return orm.Dict(scaled_structure_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple Python base data types, such as `int` or `float`, the explicit conversion to AiiDA data types can also be\n",
    "omitted, as converting them internally under the hood is possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we need to define a `calcfunction` that returns the *volumes* and *energies* of the structures, and a\n",
    "`calcfunction` that fits the EOS equation. The latter step could, in principle, also be done outside of the context of\n",
    "the `WorkChain` with a normal Python function, however, this step would then **not** be recorded in the provenance of\n",
    "the full workflow. The implementation of both `calcfunction`s is contained in the next cell, but is not that important,\n",
    "so we will just skim over it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@engine.calcfunction\n",
    "def create_eos_dictionary(**kwargs) -> orm.Dict:\n",
    "    eos = {\n",
    "        label: (result['volume'], result['energy'])\n",
    "        for label, result in kwargs.items()\n",
    "    }\n",
    "    return orm.Dict(eos)\n",
    "\n",
    "\n",
    "@engine.calcfunction\n",
    "def fit_eos(volumes: orm.Dict, scf_results: orm.Dict) -> orm.Dict:\n",
    "    \"\"\"Fit the EOS of the data.\"\"\"\n",
    "    from ase.eos import EquationOfState\n",
    "    from ase.units import kJ\n",
    "\n",
    "    volumes_list = []\n",
    "    energies = []\n",
    "    for key, data in scf_results.get_dict().items():\n",
    "        energy = data[\"energy\"]\n",
    "        energies.append(energy)\n",
    "        volumes_list.append(volumes.get_dict()[key])\n",
    "    #\n",
    "    eos = EquationOfState(volumes_list, energies)\n",
    "    v0, e0, B = eos.fit()\n",
    "    # convert B to GPa\n",
    "    B = B / kJ * 1.0e24\n",
    "    eos = {\"energy unit\": \"eV\", \"v0\": v0, \"e0\": e0, \"B\": B}\n",
    "    return orm.Dict(eos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define our `EquationOfStateWorkChain`. To this end, we inherit from `engine.WorkChain`. The main method of\n",
    "our `WorkChain` is the `define` `classmethod`. In it, we define the `input`s, `output`s, and `outline` of our workflow:\n",
    "\n",
    "```python\n",
    "```\n",
    "\n",
    "As you can see above, the outline of the workflow is quite simple: We first run the different SCF calculations, using\n",
    "the previously defined `calcfunction` to scale our input structure, and then return the results. To run the SCF\n",
    "calculations, we iterate over the scaled structures and prepare the `PwCalculation`s using the `ProcessBuilder`, as we\n",
    "did before:\n",
    "\n",
    "```python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquationOfStateWorkChain(engine.WorkChain):\n",
    "    \"\"\"WorkChain to compute Equation of State using Quantum ESPRESSO.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def define(cls, spec):\n",
    "        \"\"\"Specify inputs and outputs.\"\"\"\n",
    "        super().define(spec)\n",
    "        spec.input(\"code\", valid_type=orm.Code)\n",
    "        spec.input(\"structure\", valid_type=orm.StructureData)\n",
    "        spec.input(\"scale_factors\", valid_type=orm.List)\n",
    "\n",
    "        spec.outline(\n",
    "            cls.run_eos_scfs,\n",
    "            cls.results,\n",
    "        )\n",
    "        spec.output(\"eos_dict\", valid_type=orm.Dict)\n",
    "\n",
    "    def run_eos_scfs(self):\n",
    "\n",
    "        calcjob_dict = {}\n",
    "\n",
    "        for label, rescaled_structure in scale_structures(self.inputs.structure, self.inputs.scale_factors).items():\n",
    "\n",
    "            builder = PwCalculation.get_builder()\n",
    "            builder.code = self.inputs.code\n",
    "            builder.structure = rescaled_structure\n",
    "            builder.parameters = orm.Dict(parameters)\n",
    "            # pseudo_family = orm.load_group('SSSP/1.3/PBEsol/efficiency')\n",
    "            builder.pseudos = pseudo_family.get_pseudos(structure=rescaled_structure)\n",
    "            kpoints = orm.KpointsData()\n",
    "            kpoints.set_kpoints_mesh([2, 2, 2])\n",
    "            builder.kpoints = kpoints\n",
    "            builder.metadata.options = metadata_options\n",
    "\n",
    "            calcjob_dict[label] = self.submit(builder)\n",
    "\n",
    "        self.ctx.labels = list(calcjob_dict.keys())\n",
    "\n",
    "        return calcjob_dict\n",
    "\n",
    "    def results(self):\n",
    "\n",
    "        self.report(self.ctx)\n",
    "\n",
    "        # label: self.ctx[label].outputs['properties'] for label in self.ctx.labels\n",
    "\n",
    "        eos_results = {}\n",
    "        for label in self.ctx.labels:\n",
    "            energy = self.ctx[label].outputs.output_parameters.get_dict()['energy']\n",
    "            volume = self.ctx[label].outputs.output_parameters.get_dict()['volume']\n",
    "            eos_results[label] = orm.Dict({'energy': orm.Float(energy), 'volume': orm.Float(volume)})\n",
    "\n",
    "        eos_dict = create_eos_dictionary(**eos_results)\n",
    "        self.out('eos_dict', eos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = engine.run(\n",
    "    EquationOfStateWorkChain,\n",
    "    code=pw_code,\n",
    "    structure=si_structure,\n",
    "    scale_factors=orm.List([0.9, 0.95, 1.0, 1.05, 1.1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace this with the actual EOS fit\n",
    "\n",
    "eos_dict = results['eos_dict'].get_dict()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(\n",
    "    [e[0] for e in eos_dict.values()],\n",
    "    [v[1] for v in eos_dict.values()],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "20c30adb377910d9d5c8112cf74e9f7ecb37538254a701570d770f074373c53e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
